{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyM8DVTCLrtt1apNo3oAAPK1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#!/usr/bin/env python3\n","\"\"\"\n","Fast CPU-only DGA Feature Extraction (31 features)\n","Input:  domains.csv (must contain a column 'domain')\n","Output: features_optimized.csv\n","\"\"\"\n","\n","import re, math, string, zlib\n","import pandas as pd\n","import numpy as np\n","from collections import Counter\n","from difflib import SequenceMatcher\n","from nltk.corpus import words as nltk_words\n","import nltk\n","\n","try:\n","    nltk.data.find(\"corpora/words\")\n","except LookupError:\n","    nltk.download(\"words\")\n","\n","ENGLISH_WORDS = set(w.lower() for w in nltk_words.words())\n","VOWELS = set(\"aeiou\")\n","CONSONANTS = set(string.ascii_lowercase) - VOWELS\n","ALPHABET = string.ascii_lowercase\n","POP_DOMAINS = [\"google\", \"facebook\", \"youtube\", \"amazon\", \"twitter\", \"instagram\"]\n","\n","# Precompute key maps\n","KEYBOARD_POS = {\n","    c: (i // 10, i % 10)\n","    for i, c in enumerate(\"qwertyuiopasdfghjklzxcvbnm\")\n","}\n","\n","# --- Utility functions ---\n","def safe(s): return str(s).lower() if isinstance(s, str) else \"\"\n","\n","def shannon_entropy(s):\n","    if not s: return 0.0\n","    freq = Counter(s)\n","    probs = np.array(list(freq.values()), dtype=float) / len(s)\n","    return -np.sum(probs * np.log2(probs + 1e-12))\n","\n","def renyi_entropy(s, alpha=2):\n","    if not s: return 0.0\n","    freq = Counter(s)\n","    probs = np.array(list(freq.values()), dtype=float) / len(s)\n","    return 1.0 / (1.0 - alpha) * np.log2(np.sum(probs ** alpha) + 1e-12)\n","\n","def kolmogorov_complexity(s):\n","    if not s: return 0.0\n","    comp = zlib.compress(s.encode(\"utf-8\"))\n","    return len(comp) / max(1, len(s))\n","\n","def bigram_likelihood(s):\n","    if len(s) < 2: return 0.0\n","    bigrams = [s[i:i+2] for i in range(len(s)-1)]\n","    freq = Counter(bigrams)\n","    probs = np.array(list(freq.values())) / len(bigrams)\n","    return -np.sum(probs * np.log2(probs + 1e-12))\n","\n","def trigram_score(s):\n","    if len(s) < 3: return 0.0\n","    trigrams = [s[i:i+3] for i in range(len(s)-2)]\n","    freq = Counter(trigrams)\n","    probs = np.array(list(freq.values())) / len(trigrams)\n","    return -np.sum(probs * np.log2(probs + 1e-12))\n","\n","def char_freq_dev(s):\n","    if not s: return 0.0\n","    freq = np.array(list(Counter(s).values()))\n","    return np.std(freq / np.sum(freq))\n","\n","def char_gini(s):\n","    if not s: return 0.0\n","    freq = np.array(list(Counter(s).values()), dtype=float)\n","    p = freq / freq.sum()\n","    return 1.0 - np.sum(p**2)\n","\n","def vowel_consonant_features(s):\n","    v_runs = re.findall(r\"[aeiou]+\", s)\n","    c_runs = re.findall(r\"[bcdfghjklmnpqrstvwxyz]+\", s)\n","    v_run_count = len(v_runs)\n","    c_run_count = len(c_runs)\n","    v_cluster_ratio = max((len(r) for r in v_runs), default=0) / max(1, len(s))\n","    return v_run_count, c_run_count, v_cluster_ratio\n","\n","def max_consonant_cluster(s):\n","    clusters = re.findall(r\"[bcdfghjklmnpqrstvwxyz]+\", s)\n","    return max((len(c) for c in clusters), default=0)\n","\n","def pronounceability_score(s):\n","    if not s: return 0.0\n","    score = sum(c in VOWELS for c in s) / len(s)\n","    return score\n","\n","def unique_char_ratio(s):\n","    return len(set(s)) / max(1, len(s))\n","\n","def unique_char(s):\n","    return len(set(s))\n","\n","def dict_std(s):\n","    if not s: return 0.0\n","    words_found = sum(w in ENGLISH_WORDS for w in re.findall(r\"[a-z]+\", s))\n","    return words_found / max(1, len(s.split(\".\")))\n","\n","def markov_chain_likelihood(s):\n","    if len(s) < 2: return 0.0\n","    probs = []\n","    for i in range(1, len(s)):\n","        probs.append(1.0 if s[i] == s[i-1] else 0.5)\n","    return np.mean(probs)\n","\n","def kl_divergence(s):\n","    benign_dist = np.ones(26) / 26\n","    if not s: return 0.0\n","    counts = np.array([s.count(c) for c in ALPHABET], dtype=float)\n","    if counts.sum() == 0: return 0.0\n","    p = counts / counts.sum()\n","    return np.sum(p * np.log2((p + 1e-12) / (benign_dist + 1e-12)))\n","\n","def sliding_word_ratio(s):\n","    if len(s) < 4: return 0.0\n","    matches = sum(s[i:i+4] in ENGLISH_WORDS for i in range(len(s)-3))\n","    return matches / (len(s) - 3)\n","\n","def keyboard_distance_score(s):\n","    total = 0.0\n","    count = 0\n","    for a, b in zip(s, s[1:]):\n","        if a in KEYBOARD_POS and b in KEYBOARD_POS:\n","            pa, pb = KEYBOARD_POS[a], KEYBOARD_POS[b]\n","            total += math.dist(pa, pb)\n","            count += 1\n","    return total / count if count else 0.0\n","\n","def min_levenshtein_to_popular(s):\n","    return min(SequenceMatcher(None, s, p).ratio() for p in POP_DOMAINS)\n","\n","def repetition_ratio(s):\n","    if not s: return 0.0\n","    freq = Counter(s)\n","    return max(freq.values()) / len(s)\n","\n","def alphabetic_ratio(s):\n","    letters = sum(c.isalpha() for c in s)\n","    return letters / max(1, len(s))\n","\n","def symbol_ratio(s):\n","    symbols = sum(not c.isalnum() for c in s)\n","    return symbols / max(1, len(s))\n","\n","def entropy_per_length(s):\n","    e = shannon_entropy(s)\n","    return e / max(1, len(s))\n","\n","def entropy_slope(s):\n","    if len(s) < 2: return 0.0\n","    entropies = [shannon_entropy(s[:i]) for i in range(2, len(s)+1)]\n","    x = np.arange(2, len(s)+1)\n","    slope, _ = np.polyfit(x, entropies, 1)\n","    return slope\n","\n","def char_distribution_symmetry(s):\n","    if not s: return 0.0\n","    freq = np.array(list(Counter(s).values()), dtype=float)\n","    mean = freq.mean()\n","    return np.mean(np.abs(freq - mean)) / mean\n","\n","# === MAIN ===\n","def main(input_csv=\"dga_version5.csv\", output_csv=\"oct30_dga_v1.csv\"):\n","    df = pd.read_csv(input_csv, dtype=str)\n","    domains = df[\"domain\"].fillna(\"\").str.lower().tolist()\n","    print(f\"Processing {len(domains)} domains...\")\n","\n","    feats = []\n","    for d in domains:\n","        s = safe(d)\n","        v_run, c_run, v_ratio = vowel_consonant_features(s)\n","        feats.append({\n","            \"Maximum_Consonants_Cluster\": max_consonant_cluster(s),\n","            \"Consonant_count\": sum(c in CONSONANTS for c in s),\n","            \"Pronounceability_Score\": pronounceability_score(s),\n","            \"Bigram-Likelihood\": bigram_likelihood(s),\n","            \"Character_Frequency_Deviation\": char_freq_dev(s),\n","            \"Unique_Character_Ratio\": unique_char_ratio(s),\n","            \"Unique_Character\": unique_char(s),\n","            \"Dictionary_Standard\": dict_std(s),\n","            \"Markov_Chain_Likelihood\": markov_chain_likelihood(s),\n","            \"Length\": len(s),\n","            \"Compression_Ratio\": kolmogorov_complexity(s),\n","            \"Bigram_Score\": bigram_likelihood(s),\n","            \"Trigram_Score\": trigram_score(s),\n","            \"N-gram_LM_perplexity\": bigram_likelihood(s) + trigram_score(s),\n","            \"Normal_Character_Frequency_varience\": char_freq_dev(s),\n","            \"Character_Gini\": char_gini(s),\n","            \"KL_Divergence\": kl_divergence(s),\n","            \"Sliding_word_ratio\": sliding_word_ratio(s),\n","            \"Kolmogorov_Complexity\": kolmogorov_complexity(s),\n","            \"Renyi_Entropy\": renyi_entropy(s),\n","            \"Keyboard_Distance_Score\": keyboard_distance_score(s),\n","            \"Min_Levenshtein_To_Popular\": min_levenshtein_to_popular(s),\n","            \"Repetition_Ratio\": repetition_ratio(s),\n","            \"Alphabetic_Ratio\": alphabetic_ratio(s),\n","            \"Symbol_Ratio\": symbol_ratio(s),\n","            \"Vowel_run_count\": v_run,\n","            \"Consonant_run_count\": c_run,\n","            \"Vowel_cluster_ratio\": v_ratio,\n","            \"Entropy_per_length\": entropy_per_length(s),\n","            \"Entropy_Slope\": entropy_slope(s),\n","            \"Character_Distribution_Symmetry\": char_distribution_symmetry(s),\n","        })\n","\n","    feat_df = pd.DataFrame(feats)\n","    out = pd.concat([df, feat_df], axis=1)\n","    out.to_csv(output_csv, index=False)\n","    print(f\"✅ Features saved to {output_csv}\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7UzBdgc7dg7o","executionInfo":{"status":"ok","timestamp":1761817598109,"user_tz":-330,"elapsed":810060,"user":{"displayName":"Manoj M J","userId":"05788064290666556527"}},"outputId":"778414b4-9f92-417c-f2d6-8b914de7f188"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing 694173 domains...\n","✅ Features saved to features_optimized.csv\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"oct30_dga_v1.csv\")"],"metadata":{"id":"VnNB8oQolqEG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df=pd.read_csv('oct30_dga_v1.csv')\n","df.describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367},"id":"CIbawNAaikL9","executionInfo":{"status":"ok","timestamp":1761818329055,"user_tz":-330,"elapsed":6759,"user":{"displayName":"Manoj M J","userId":"05788064290666556527"}},"outputId":"53a7d371-35b3-464a-d93b-69dd57b69c23"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          label  Maximum_Consonants_Cluster  Consonant_count  \\\n","count  694173.0               694173.000000    694173.000000   \n","mean        1.0                    4.576519        12.200742   \n","std         0.0                    2.643387         4.305605   \n","min         1.0                    1.000000         2.000000   \n","25%         1.0                    3.000000         9.000000   \n","50%         1.0                    4.000000        12.000000   \n","75%         1.0                    6.000000        15.000000   \n","max         1.0                   16.000000        27.000000   \n","\n","       Pronounceability_Score  Bigram-Likelihood  \\\n","count           694173.000000      694173.000000   \n","mean                 0.298728           4.020743   \n","std                  0.117054           0.521081   \n","min                  0.000000           2.370951   \n","25%                  0.200000           3.664498   \n","50%                  0.321429           4.037401   \n","75%                  0.375000           4.436605   \n","max                  0.800000           5.247928   \n","\n","       Character_Frequency_Deviation  Unique_Character_Ratio  \\\n","count                  694173.000000           694173.000000   \n","mean                        0.036880                0.691829   \n","std                         0.012843                0.143928   \n","min                         0.000000                0.305556   \n","25%                         0.029215                0.566667   \n","50%                         0.036666                0.687500   \n","75%                         0.042855                0.812500   \n","max                         0.177778                1.000000   \n","\n","       Unique_Character  Dictionary_Standard  Markov_Chain_Likelihood  ...  \\\n","count     694173.000000        694173.000000            694173.000000  ...   \n","mean          12.481366             0.040699                 0.518253  ...   \n","std            2.689910             0.146950                 0.024762  ...   \n","min            4.000000             0.000000                 0.500000  ...   \n","25%           10.000000             0.000000                 0.500000  ...   \n","50%           12.000000             0.000000                 0.500000  ...   \n","75%           14.000000             0.000000                 0.533333  ...   \n","max           26.000000             4.000000                 0.812500  ...   \n","\n","       Min_Levenshtein_To_Popular  Repetition_Ratio  Alphabetic_Ratio  \\\n","count               694173.000000     694173.000000     694173.000000   \n","mean                     0.084301          0.168355          0.939118   \n","std                      0.036036          0.044974          0.024891   \n","min                      0.000000          0.052632          0.406250   \n","25%                      0.068966          0.133333          0.923077   \n","50%                      0.086957          0.166667          0.941176   \n","75%                      0.105263          0.187500          0.960000   \n","max                      0.266667          0.555556          0.975000   \n","\n","        Symbol_Ratio  Vowel_run_count  Consonant_run_count  \\\n","count  694173.000000    694173.000000        694173.000000   \n","mean        0.060405         5.068241             6.144378   \n","std         0.022564         2.953502             3.084483   \n","min         0.025000         0.000000             1.000000   \n","25%         0.040000         3.000000             4.000000   \n","50%         0.058824         4.000000             5.000000   \n","75%         0.076923         8.000000             9.000000   \n","max         0.125000        17.000000            17.000000   \n","\n","       Vowel_cluster_ratio  Entropy_per_length  Entropy_Slope  \\\n","count        694173.000000       694173.000000  694173.000000   \n","mean              0.092197            0.200827       0.144334   \n","std               0.048756            0.060460       0.060895   \n","min               0.000000            0.089459       0.030941   \n","25%               0.062500            0.146931       0.089846   \n","50%               0.076923            0.198916       0.139890   \n","75%               0.105263            0.242187       0.188662   \n","max               0.700000            0.375000       0.444796   \n","\n","       Character_Distribution_Symmetry  \n","count                    694173.000000  \n","mean                          0.361636  \n","std                           0.120434  \n","min                           0.000000  \n","25%                           0.288462  \n","50%                           0.375940  \n","75%                           0.448276  \n","max                           0.807692  \n","\n","[8 rows x 32 columns]"],"text/html":["\n","  <div id=\"df-3e3d979e-754f-4c2c-aa9c-3dc274d368f2\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>Maximum_Consonants_Cluster</th>\n","      <th>Consonant_count</th>\n","      <th>Pronounceability_Score</th>\n","      <th>Bigram-Likelihood</th>\n","      <th>Character_Frequency_Deviation</th>\n","      <th>Unique_Character_Ratio</th>\n","      <th>Unique_Character</th>\n","      <th>Dictionary_Standard</th>\n","      <th>Markov_Chain_Likelihood</th>\n","      <th>...</th>\n","      <th>Min_Levenshtein_To_Popular</th>\n","      <th>Repetition_Ratio</th>\n","      <th>Alphabetic_Ratio</th>\n","      <th>Symbol_Ratio</th>\n","      <th>Vowel_run_count</th>\n","      <th>Consonant_run_count</th>\n","      <th>Vowel_cluster_ratio</th>\n","      <th>Entropy_per_length</th>\n","      <th>Entropy_Slope</th>\n","      <th>Character_Distribution_Symmetry</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>694173.0</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>...</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>1.0</td>\n","      <td>4.576519</td>\n","      <td>12.200742</td>\n","      <td>0.298728</td>\n","      <td>4.020743</td>\n","      <td>0.036880</td>\n","      <td>0.691829</td>\n","      <td>12.481366</td>\n","      <td>0.040699</td>\n","      <td>0.518253</td>\n","      <td>...</td>\n","      <td>0.084301</td>\n","      <td>0.168355</td>\n","      <td>0.939118</td>\n","      <td>0.060405</td>\n","      <td>5.068241</td>\n","      <td>6.144378</td>\n","      <td>0.092197</td>\n","      <td>0.200827</td>\n","      <td>0.144334</td>\n","      <td>0.361636</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.0</td>\n","      <td>2.643387</td>\n","      <td>4.305605</td>\n","      <td>0.117054</td>\n","      <td>0.521081</td>\n","      <td>0.012843</td>\n","      <td>0.143928</td>\n","      <td>2.689910</td>\n","      <td>0.146950</td>\n","      <td>0.024762</td>\n","      <td>...</td>\n","      <td>0.036036</td>\n","      <td>0.044974</td>\n","      <td>0.024891</td>\n","      <td>0.022564</td>\n","      <td>2.953502</td>\n","      <td>3.084483</td>\n","      <td>0.048756</td>\n","      <td>0.060460</td>\n","      <td>0.060895</td>\n","      <td>0.120434</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.0</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>0.000000</td>\n","      <td>2.370951</td>\n","      <td>0.000000</td>\n","      <td>0.305556</td>\n","      <td>4.000000</td>\n","      <td>0.000000</td>\n","      <td>0.500000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.052632</td>\n","      <td>0.406250</td>\n","      <td>0.025000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.089459</td>\n","      <td>0.030941</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>1.0</td>\n","      <td>3.000000</td>\n","      <td>9.000000</td>\n","      <td>0.200000</td>\n","      <td>3.664498</td>\n","      <td>0.029215</td>\n","      <td>0.566667</td>\n","      <td>10.000000</td>\n","      <td>0.000000</td>\n","      <td>0.500000</td>\n","      <td>...</td>\n","      <td>0.068966</td>\n","      <td>0.133333</td>\n","      <td>0.923077</td>\n","      <td>0.040000</td>\n","      <td>3.000000</td>\n","      <td>4.000000</td>\n","      <td>0.062500</td>\n","      <td>0.146931</td>\n","      <td>0.089846</td>\n","      <td>0.288462</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>1.0</td>\n","      <td>4.000000</td>\n","      <td>12.000000</td>\n","      <td>0.321429</td>\n","      <td>4.037401</td>\n","      <td>0.036666</td>\n","      <td>0.687500</td>\n","      <td>12.000000</td>\n","      <td>0.000000</td>\n","      <td>0.500000</td>\n","      <td>...</td>\n","      <td>0.086957</td>\n","      <td>0.166667</td>\n","      <td>0.941176</td>\n","      <td>0.058824</td>\n","      <td>4.000000</td>\n","      <td>5.000000</td>\n","      <td>0.076923</td>\n","      <td>0.198916</td>\n","      <td>0.139890</td>\n","      <td>0.375940</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>1.0</td>\n","      <td>6.000000</td>\n","      <td>15.000000</td>\n","      <td>0.375000</td>\n","      <td>4.436605</td>\n","      <td>0.042855</td>\n","      <td>0.812500</td>\n","      <td>14.000000</td>\n","      <td>0.000000</td>\n","      <td>0.533333</td>\n","      <td>...</td>\n","      <td>0.105263</td>\n","      <td>0.187500</td>\n","      <td>0.960000</td>\n","      <td>0.076923</td>\n","      <td>8.000000</td>\n","      <td>9.000000</td>\n","      <td>0.105263</td>\n","      <td>0.242187</td>\n","      <td>0.188662</td>\n","      <td>0.448276</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1.0</td>\n","      <td>16.000000</td>\n","      <td>27.000000</td>\n","      <td>0.800000</td>\n","      <td>5.247928</td>\n","      <td>0.177778</td>\n","      <td>1.000000</td>\n","      <td>26.000000</td>\n","      <td>4.000000</td>\n","      <td>0.812500</td>\n","      <td>...</td>\n","      <td>0.266667</td>\n","      <td>0.555556</td>\n","      <td>0.975000</td>\n","      <td>0.125000</td>\n","      <td>17.000000</td>\n","      <td>17.000000</td>\n","      <td>0.700000</td>\n","      <td>0.375000</td>\n","      <td>0.444796</td>\n","      <td>0.807692</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 32 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e3d979e-754f-4c2c-aa9c-3dc274d368f2')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-3e3d979e-754f-4c2c-aa9c-3dc274d368f2 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-3e3d979e-754f-4c2c-aa9c-3dc274d368f2');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-6a4f6361-a09a-44c4-ba6f-e51714d5d222\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6a4f6361-a09a-44c4-ba6f-e51714d5d222')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-6a4f6361-a09a-44c4-ba6f-e51714d5d222 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["import pandas as pd\n","\n","def reorder_columns(input_csv, output_csv, desired_order):\n","    \"\"\"\n","    Reorder the columns of a CSV file based on user-defined order.\n","\n","    Parameters:\n","    - input_csv (str): Path to input CSV file.\n","    - output_csv (str): Path to output CSV file with reordered columns.\n","    - desired_order (list): List of column names in the desired order.\n","    \"\"\"\n","    # Load dataset\n","    df = pd.read_csv(input_csv)\n","\n","    # Check which desired columns exist\n","    available_columns = [col for col in desired_order if col in df.columns]\n","\n","    # Add missing columns (if any were not in df)\n","    missing_columns = [col for col in desired_order if col not in df.columns]\n","    for col in missing_columns:\n","        df[col] = None  # Fill with None or default values\n","\n","    # Reorder\n","    df = df[available_columns + [col for col in df.columns if col not in available_columns]]\n","\n","    # Save output\n","    df.to_csv(output_csv, index=False)\n","    print(f\"✅ Reordered CSV saved as {output_csv}\")\n","\n","\n","# =====================\n","# Example usage\n","# =====================\n","\n","# Suppose your dataset has 58 features + \"domain\" + \"label\"\n","input_csv = \"oct30_dga_v1.csv\"\n","output_csv = \"oct30_dga_v2.csv\"\n","\n","# User-defined column order (just an example)\n","desired_order = [\n","\n","\n","\n","\n","\n","\"domain\",\n","\"Maximum_Consonants_Cluster\",\n","\"Consonant_count\",\n","\"Pronounceability_Score\",\n","\"Bigram-Likelihood\",\n","\"Character_Frequency_Deviation\",\n","\"Unique_Character_Ratio\",\n","\"Unique_Character\",\n","\"Dictionary_Standard\",\n","\"Markov_Chain_Likelihood\",\n","\"Length\",\n","\"Compression_Ratio\",\n","\"Bigram_Score\",\n","\"Trigram_Score\",\n","\"N-gram_LM_perplexity\",\n","\"Normal_Character_Frequency_varience\",\n","\"Character_Gini\",\n","\"KL_Divergence\",\n","\"Sliding_word_ratio\",\n","\"Kolmogorov_Complexity\",\n","\"Renyi_Entropy\",\n","\"Keyboard_Distance_Score\",\n","\"Min_Levenshtein_To_Popular\",\n","\"Repetition_Ratio\",\n","\"Alphabetic_Ratio\",\n","\"Symbol_Ratio\",\n","\"Vowel_run_count\",\n","\"Consonant_run_count\",\n","\"Vowel_cluster_ratio\",\n","\"Entropy_per_length\",\n","\"Entropy_Slope\",\n","\"Character_Distribution_Symmetry\",\n","\"label\"\n","\n","]\n","\n","# Reorder dataset\n","reorder_columns(input_csv, output_csv, desired_order)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UPvw9NuXl2R9","executionInfo":{"status":"ok","timestamp":1761820163056,"user_tz":-330,"elapsed":36574,"user":{"displayName":"Manoj M J","userId":"05788064290666556527"}},"outputId":"411335c3-8fd4-4052-d543-52933e4fe7b8"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Reordered CSV saved as oct30_dga_v2.csv\n"]}]},{"cell_type":"code","source":["df=pd.read_csv('oct30_dga_v2.csv')\n","df.describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367},"id":"UuRtQClMna36","executionInfo":{"status":"ok","timestamp":1761820170309,"user_tz":-330,"elapsed":4925,"user":{"displayName":"Manoj M J","userId":"05788064290666556527"}},"outputId":"7d79bb65-ef12-4a8e-cbde-e57ede5bf3a8"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Maximum_Consonants_Cluster  Consonant_count  Pronounceability_Score  \\\n","count               694173.000000    694173.000000           694173.000000   \n","mean                     4.576519        12.200742                0.298728   \n","std                      2.643387         4.305605                0.117054   \n","min                      1.000000         2.000000                0.000000   \n","25%                      3.000000         9.000000                0.200000   \n","50%                      4.000000        12.000000                0.321429   \n","75%                      6.000000        15.000000                0.375000   \n","max                     16.000000        27.000000                0.800000   \n","\n","       Bigram-Likelihood  Character_Frequency_Deviation  \\\n","count      694173.000000                  694173.000000   \n","mean            4.020743                       0.036880   \n","std             0.521081                       0.012843   \n","min             2.370951                       0.000000   \n","25%             3.664498                       0.029215   \n","50%             4.037401                       0.036666   \n","75%             4.436605                       0.042855   \n","max             5.247928                       0.177778   \n","\n","       Unique_Character_Ratio  Unique_Character  Dictionary_Standard  \\\n","count           694173.000000     694173.000000        694173.000000   \n","mean                 0.691829         12.481366             0.040699   \n","std                  0.143928          2.689910             0.146950   \n","min                  0.305556          4.000000             0.000000   \n","25%                  0.566667         10.000000             0.000000   \n","50%                  0.687500         12.000000             0.000000   \n","75%                  0.812500         14.000000             0.000000   \n","max                  1.000000         26.000000             4.000000   \n","\n","       Markov_Chain_Likelihood         Length  ...  Repetition_Ratio  \\\n","count            694173.000000  694173.000000  ...     694173.000000   \n","mean                  0.518253      19.226092  ...          0.168355   \n","std                   0.024762       6.938378  ...          0.044974   \n","min                   0.500000       8.000000  ...          0.052632   \n","25%                   0.500000      14.000000  ...          0.133333   \n","50%                   0.500000      18.000000  ...          0.166667   \n","75%                   0.533333      25.000000  ...          0.187500   \n","max                   0.812500      40.000000  ...          0.555556   \n","\n","       Alphabetic_Ratio   Symbol_Ratio  Vowel_run_count  Consonant_run_count  \\\n","count     694173.000000  694173.000000    694173.000000        694173.000000   \n","mean           0.939118       0.060405         5.068241             6.144378   \n","std            0.024891       0.022564         2.953502             3.084483   \n","min            0.406250       0.025000         0.000000             1.000000   \n","25%            0.923077       0.040000         3.000000             4.000000   \n","50%            0.941176       0.058824         4.000000             5.000000   \n","75%            0.960000       0.076923         8.000000             9.000000   \n","max            0.975000       0.125000        17.000000            17.000000   \n","\n","       Vowel_cluster_ratio  Entropy_per_length  Entropy_Slope  \\\n","count        694173.000000       694173.000000  694173.000000   \n","mean              0.092197            0.200827       0.144334   \n","std               0.048756            0.060460       0.060895   \n","min               0.000000            0.089459       0.030941   \n","25%               0.062500            0.146931       0.089846   \n","50%               0.076923            0.198916       0.139890   \n","75%               0.105263            0.242187       0.188662   \n","max               0.700000            0.375000       0.444796   \n","\n","       Character_Distribution_Symmetry     label  \n","count                    694173.000000  694173.0  \n","mean                          0.361636       1.0  \n","std                           0.120434       0.0  \n","min                           0.000000       1.0  \n","25%                           0.288462       1.0  \n","50%                           0.375940       1.0  \n","75%                           0.448276       1.0  \n","max                           0.807692       1.0  \n","\n","[8 rows x 32 columns]"],"text/html":["\n","  <div id=\"df-dd5e757f-0084-4e64-a96e-8684d1d07127\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Maximum_Consonants_Cluster</th>\n","      <th>Consonant_count</th>\n","      <th>Pronounceability_Score</th>\n","      <th>Bigram-Likelihood</th>\n","      <th>Character_Frequency_Deviation</th>\n","      <th>Unique_Character_Ratio</th>\n","      <th>Unique_Character</th>\n","      <th>Dictionary_Standard</th>\n","      <th>Markov_Chain_Likelihood</th>\n","      <th>Length</th>\n","      <th>...</th>\n","      <th>Repetition_Ratio</th>\n","      <th>Alphabetic_Ratio</th>\n","      <th>Symbol_Ratio</th>\n","      <th>Vowel_run_count</th>\n","      <th>Consonant_run_count</th>\n","      <th>Vowel_cluster_ratio</th>\n","      <th>Entropy_per_length</th>\n","      <th>Entropy_Slope</th>\n","      <th>Character_Distribution_Symmetry</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>...</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.000000</td>\n","      <td>694173.0</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>4.576519</td>\n","      <td>12.200742</td>\n","      <td>0.298728</td>\n","      <td>4.020743</td>\n","      <td>0.036880</td>\n","      <td>0.691829</td>\n","      <td>12.481366</td>\n","      <td>0.040699</td>\n","      <td>0.518253</td>\n","      <td>19.226092</td>\n","      <td>...</td>\n","      <td>0.168355</td>\n","      <td>0.939118</td>\n","      <td>0.060405</td>\n","      <td>5.068241</td>\n","      <td>6.144378</td>\n","      <td>0.092197</td>\n","      <td>0.200827</td>\n","      <td>0.144334</td>\n","      <td>0.361636</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>2.643387</td>\n","      <td>4.305605</td>\n","      <td>0.117054</td>\n","      <td>0.521081</td>\n","      <td>0.012843</td>\n","      <td>0.143928</td>\n","      <td>2.689910</td>\n","      <td>0.146950</td>\n","      <td>0.024762</td>\n","      <td>6.938378</td>\n","      <td>...</td>\n","      <td>0.044974</td>\n","      <td>0.024891</td>\n","      <td>0.022564</td>\n","      <td>2.953502</td>\n","      <td>3.084483</td>\n","      <td>0.048756</td>\n","      <td>0.060460</td>\n","      <td>0.060895</td>\n","      <td>0.120434</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>0.000000</td>\n","      <td>2.370951</td>\n","      <td>0.000000</td>\n","      <td>0.305556</td>\n","      <td>4.000000</td>\n","      <td>0.000000</td>\n","      <td>0.500000</td>\n","      <td>8.000000</td>\n","      <td>...</td>\n","      <td>0.052632</td>\n","      <td>0.406250</td>\n","      <td>0.025000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.089459</td>\n","      <td>0.030941</td>\n","      <td>0.000000</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>3.000000</td>\n","      <td>9.000000</td>\n","      <td>0.200000</td>\n","      <td>3.664498</td>\n","      <td>0.029215</td>\n","      <td>0.566667</td>\n","      <td>10.000000</td>\n","      <td>0.000000</td>\n","      <td>0.500000</td>\n","      <td>14.000000</td>\n","      <td>...</td>\n","      <td>0.133333</td>\n","      <td>0.923077</td>\n","      <td>0.040000</td>\n","      <td>3.000000</td>\n","      <td>4.000000</td>\n","      <td>0.062500</td>\n","      <td>0.146931</td>\n","      <td>0.089846</td>\n","      <td>0.288462</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>4.000000</td>\n","      <td>12.000000</td>\n","      <td>0.321429</td>\n","      <td>4.037401</td>\n","      <td>0.036666</td>\n","      <td>0.687500</td>\n","      <td>12.000000</td>\n","      <td>0.000000</td>\n","      <td>0.500000</td>\n","      <td>18.000000</td>\n","      <td>...</td>\n","      <td>0.166667</td>\n","      <td>0.941176</td>\n","      <td>0.058824</td>\n","      <td>4.000000</td>\n","      <td>5.000000</td>\n","      <td>0.076923</td>\n","      <td>0.198916</td>\n","      <td>0.139890</td>\n","      <td>0.375940</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>6.000000</td>\n","      <td>15.000000</td>\n","      <td>0.375000</td>\n","      <td>4.436605</td>\n","      <td>0.042855</td>\n","      <td>0.812500</td>\n","      <td>14.000000</td>\n","      <td>0.000000</td>\n","      <td>0.533333</td>\n","      <td>25.000000</td>\n","      <td>...</td>\n","      <td>0.187500</td>\n","      <td>0.960000</td>\n","      <td>0.076923</td>\n","      <td>8.000000</td>\n","      <td>9.000000</td>\n","      <td>0.105263</td>\n","      <td>0.242187</td>\n","      <td>0.188662</td>\n","      <td>0.448276</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>16.000000</td>\n","      <td>27.000000</td>\n","      <td>0.800000</td>\n","      <td>5.247928</td>\n","      <td>0.177778</td>\n","      <td>1.000000</td>\n","      <td>26.000000</td>\n","      <td>4.000000</td>\n","      <td>0.812500</td>\n","      <td>40.000000</td>\n","      <td>...</td>\n","      <td>0.555556</td>\n","      <td>0.975000</td>\n","      <td>0.125000</td>\n","      <td>17.000000</td>\n","      <td>17.000000</td>\n","      <td>0.700000</td>\n","      <td>0.375000</td>\n","      <td>0.444796</td>\n","      <td>0.807692</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 32 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd5e757f-0084-4e64-a96e-8684d1d07127')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-dd5e757f-0084-4e64-a96e-8684d1d07127 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-dd5e757f-0084-4e64-a96e-8684d1d07127');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-75615db2-2f81-45d3-a5a8-2b8d23b37afa\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-75615db2-2f81-45d3-a5a8-2b8d23b37afa')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-75615db2-2f81-45d3-a5a8-2b8d23b37afa button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["import pandas as pd\n","\n","def filter_outliers(df, feature_cols, method=\"iqr\", z_thresh=3, save_path=None):\n","    \"\"\"\n","    Filters datapoints outside the lower/upper bound for each feature\n","    and optionally saves the datapoints that are within the bounds.\n","\n","    Parameters:\n","    -----------\n","    df : pd.DataFrame\n","        Input dataset with features.\n","    feature_cols : list\n","        List of feature columns to check.\n","    method : str\n","        \"iqr\" (default) -> Interquartile Range method\n","        \"zscore\" -> Standard deviation based\n","    z_thresh : int\n","        Threshold for zscore method\n","    save_path : str or None\n","        If provided, saves the filtered dataset to this CSV path.\n","\n","    Returns:\n","    --------\n","    pd.DataFrame : Filtered dataset (within bounds)\n","    pd.DataFrame : Bounds for each feature\n","    \"\"\"\n","    bounds = {}\n","    df_filtered = df.copy()\n","\n","    for col in feature_cols:\n","        if col not in df.columns:\n","            continue  # skip missing features\n","\n","        series = df[col].dropna()\n","\n","        if method == \"iqr\":\n","            Q1 = series.quantile(0.25)\n","            Q3 = series.quantile(0.75)\n","            IQR = Q3 - Q1\n","            lower = Q1 - 1.5 * IQR\n","            upper = Q3 + 1.5 * IQR\n","\n","        elif method == \"zscore\":\n","            mean = series.mean()\n","            std = series.std()\n","            lower = mean - z_thresh * std\n","            upper = mean + z_thresh * std\n","\n","        else:\n","            raise ValueError(\"Method must be 'iqr' or 'zscore'\")\n","\n","        bounds[col] = (lower, upper)\n","\n","        # keep only rows within bounds\n","        df_filtered = df_filtered[(df_filtered[col] >= lower) & (df_filtered[col] <= upper)]\n","\n","    bounds_df = pd.DataFrame(bounds, index=[\"Lower_Bound\", \"Upper_Bound\"]).T\n","\n","    # Save filtered dataset if save_path provided\n","    if save_path:\n","        df_filtered.to_csv(save_path, index=False)\n","        print(f\"✅ Filtered dataset (within bounds) saved to {save_path}\")\n","\n","    return df_filtered.reset_index(drop=True), bounds_df\n","\n","\n","# ==== Example Usage ====\n","all_features = [\n","\n","\"Maximum_Consonants_Cluster\",\n","\"Consonant_count\",\n","\"Pronounceability_Score\",\n","\"Bigram-Likelihood\",\n","\"Character_Frequency_Deviation\",\n","\"Unique_Character_Ratio\",\n","\"Unique_Character\",\n","\"Dictionary_Standard\",\n","\"Markov_Chain_Likelihood\",\n","\"Length\",\n","\"Compression_Ratio\",\n","\"Bigram_Score\",\n","\"Trigram_Score\",\n","\"N-gram_LM_perplexity\",\n","\"Normal_Character_Frequency_varience\",\n","\"Character_Gini\",\n","\"KL_Divergence\",\n","\"Sliding_word_ratio\",\n","\"Kolmogorov_Complexity\",\n","\"Renyi_Entropy\",\n","\"Keyboard_Distance_Score\",\n","\"Min_Levenshtein_To_Popular\",\n","\"Repetition_Ratio\",\n","\"Alphabetic_Ratio\",\n","\"Symbol_Ratio\",\n","\"Vowel_run_count\",\n","\"Consonant_run_count\",\n","\"Vowel_cluster_ratio\",\n","\"Entropy_per_length\",\n","\"Entropy_Slope\",\n","\"Character_Distribution_Symmetry\"\n","\n","\n","\n","\n","]\n","\n","df = pd.read_csv(\"oct30_dga_v2.csv\")\n","# Remove duplicate columns (keep first occurrence)\n","df = df.loc[:, ~df.columns.duplicated()]\n","\n","# Save filtered data to CSV\n","df_filtered, bounds = filter_outliers(\n","    df, all_features, method=\"iqr\", save_path=\"oct30_dga_v3.csv\"\n",")\n","\n","print(bounds)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9RuYmp8XncyP","executionInfo":{"status":"ok","timestamp":1761820221110,"user_tz":-330,"elapsed":27715,"user":{"displayName":"Manoj M J","userId":"05788064290666556527"}},"outputId":"8e831bde-6920-4a4f-a3c8-42da75e394ce"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Filtered dataset (within bounds) saved to oct30_dga_v3.csv\n","                                     Lower_Bound  Upper_Bound\n","Maximum_Consonants_Cluster             -1.500000    10.500000\n","Consonant_count                         0.000000    24.000000\n","Pronounceability_Score                 -0.062500     0.637500\n","Bigram-Likelihood                       2.506336     5.594767\n","Character_Frequency_Deviation           0.008755     0.063315\n","Unique_Character_Ratio                  0.197917     1.181250\n","Unique_Character                        4.000000    20.000000\n","Dictionary_Standard                     0.000000     0.000000\n","Markov_Chain_Likelihood                 0.450000     0.583333\n","Length                                 -2.500000    41.500000\n","Compression_Ratio                       0.942857     1.948571\n","Bigram_Score                            2.506336     5.594767\n","Trigram_Score                           2.273259     5.771135\n","N-gram_LM_perplexity                    4.800719    11.426541\n","Normal_Character_Frequency_varience     0.008755     0.063315\n","Character_Gini                          0.847841     0.953795\n","KL_Divergence                           0.406904     2.281476\n","Sliding_word_ratio                     -0.176471     0.294118\n","Kolmogorov_Complexity                   0.942857     1.948571\n","Renyi_Entropy                           2.571527     4.121993\n","Keyboard_Distance_Score                 1.946508     4.877562\n","Min_Levenshtein_To_Popular              0.014519     0.159710\n","Repetition_Ratio                        0.052083     0.268750\n","Alphabetic_Ratio                        0.867692     1.015385\n","Symbol_Ratio                           -0.015385     0.132308\n","Vowel_run_count                        -4.500000    15.500000\n","Consonant_run_count                    -3.500000    16.500000\n","Vowel_cluster_ratio                    -0.001645     0.169408\n","Entropy_per_length                      0.004046     0.385073\n","Entropy_Slope                          -0.058379     0.336888\n","Character_Distribution_Symmetry         0.048740     0.687997\n"]}]},{"cell_type":"code","source":["df=pd.read_csv('oct30_dga_v3.csv')\n","df.describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367},"id":"xJ85HVP2n6j6","executionInfo":{"status":"ok","timestamp":1761820239945,"user_tz":-330,"elapsed":4743,"user":{"displayName":"Manoj M J","userId":"05788064290666556527"}},"outputId":"d35f2078-5abe-49cb-eeb7-d5188c1c7ff9"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Maximum_Consonants_Cluster  Consonant_count  Pronounceability_Score  \\\n","count               446419.000000    446419.000000           446419.000000   \n","mean                     4.353867        13.693187                0.308617   \n","std                      2.017143         3.842061                0.093463   \n","min                      1.000000         4.000000                0.000000   \n","25%                      3.000000        11.000000                0.250000   \n","50%                      4.000000        13.000000                0.333333   \n","75%                      5.000000        17.000000                0.375000   \n","max                     10.000000        24.000000                0.600000   \n","\n","       Bigram-Likelihood  Character_Frequency_Deviation  \\\n","count      446419.000000                  446419.000000   \n","mean            4.219672                       0.036251   \n","std             0.452189                       0.008934   \n","min             2.921928                       0.012056   \n","25%             3.906891                       0.029463   \n","50%             4.247928                       0.035977   \n","75%             4.606739                       0.041660   \n","max             5.247928                       0.063315   \n","\n","       Unique_Character_Ratio  Unique_Character  Dictionary_Standard  \\\n","count           446419.000000     446419.000000             446419.0   \n","mean                 0.650148         13.377294                  0.0   \n","std                  0.134842          2.387391                  0.0   \n","min                  0.305556          8.000000                  0.0   \n","25%                  0.545455         12.000000                  0.0   \n","50%                  0.620690         13.000000                  0.0   \n","75%                  0.750000         15.000000                  0.0   \n","max                  0.947368         20.000000                  0.0   \n","\n","       Markov_Chain_Likelihood         Length  ...  Repetition_Ratio  \\\n","count            446419.000000  446419.000000  ...     446419.000000   \n","mean                  0.516887      21.749233  ...          0.160256   \n","std                   0.020204       6.705792  ...          0.034522   \n","min                   0.500000       9.000000  ...          0.066667   \n","25%                   0.500000      16.000000  ...          0.129032   \n","50%                   0.514706      20.000000  ...          0.156250   \n","75%                   0.531250      28.000000  ...          0.187500   \n","max                   0.580645      40.000000  ...          0.266667   \n","\n","       Alphabetic_Ratio   Symbol_Ratio  Vowel_run_count  Consonant_run_count  \\\n","count     446419.000000  446419.000000    446419.000000        446419.000000   \n","mean           0.947611       0.052378         6.067665             7.151900   \n","std            0.019341       0.019339         2.978324             3.210679   \n","min            0.888889       0.025000         0.000000             2.000000   \n","25%            0.937500       0.035714         4.000000             4.000000   \n","50%            0.950000       0.050000         5.000000             6.000000   \n","75%            0.964286       0.062500         9.000000            10.000000   \n","max            0.975000       0.111111        15.000000            16.000000   \n","\n","       Vowel_cluster_ratio  Entropy_per_length  Entropy_Slope  \\\n","count        446419.000000       446419.000000  446419.000000   \n","mean              0.078718            0.179045       0.123232   \n","std               0.029853            0.052316       0.052670   \n","min               0.000000            0.089459       0.030941   \n","25%               0.062500            0.133325       0.078893   \n","50%               0.068966            0.170185       0.109683   \n","75%               0.100000            0.215801       0.158928   \n","max               0.166667            0.327523       0.336816   \n","\n","       Character_Distribution_Symmetry     label  \n","count                    446419.000000  446419.0  \n","mean                          0.388791       1.0  \n","std                           0.102570       0.0  \n","min                           0.099415       1.0  \n","25%                           0.329670       1.0  \n","50%                           0.400000       1.0  \n","75%                           0.463602       1.0  \n","max                           0.687831       1.0  \n","\n","[8 rows x 32 columns]"],"text/html":["\n","  <div id=\"df-893313a6-5175-4627-bd4c-af4c60ff967e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Maximum_Consonants_Cluster</th>\n","      <th>Consonant_count</th>\n","      <th>Pronounceability_Score</th>\n","      <th>Bigram-Likelihood</th>\n","      <th>Character_Frequency_Deviation</th>\n","      <th>Unique_Character_Ratio</th>\n","      <th>Unique_Character</th>\n","      <th>Dictionary_Standard</th>\n","      <th>Markov_Chain_Likelihood</th>\n","      <th>Length</th>\n","      <th>...</th>\n","      <th>Repetition_Ratio</th>\n","      <th>Alphabetic_Ratio</th>\n","      <th>Symbol_Ratio</th>\n","      <th>Vowel_run_count</th>\n","      <th>Consonant_run_count</th>\n","      <th>Vowel_cluster_ratio</th>\n","      <th>Entropy_per_length</th>\n","      <th>Entropy_Slope</th>\n","      <th>Character_Distribution_Symmetry</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>446419.000000</td>\n","      <td>446419.000000</td>\n","      <td>446419.000000</td>\n","      <td>446419.000000</td>\n","      <td>446419.000000</td>\n","      <td>446419.000000</td>\n","      <td>446419.000000</td>\n","      <td>446419.0</td>\n","      <td>446419.000000</td>\n","      <td>446419.000000</td>\n","      <td>...</td>\n","      <td>446419.000000</td>\n","      <td>446419.000000</td>\n","      <td>446419.000000</td>\n","      <td>446419.000000</td>\n","      <td>446419.000000</td>\n","      <td>446419.000000</td>\n","      <td>446419.000000</td>\n","      <td>446419.000000</td>\n","      <td>446419.000000</td>\n","      <td>446419.0</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>4.353867</td>\n","      <td>13.693187</td>\n","      <td>0.308617</td>\n","      <td>4.219672</td>\n","      <td>0.036251</td>\n","      <td>0.650148</td>\n","      <td>13.377294</td>\n","      <td>0.0</td>\n","      <td>0.516887</td>\n","      <td>21.749233</td>\n","      <td>...</td>\n","      <td>0.160256</td>\n","      <td>0.947611</td>\n","      <td>0.052378</td>\n","      <td>6.067665</td>\n","      <td>7.151900</td>\n","      <td>0.078718</td>\n","      <td>0.179045</td>\n","      <td>0.123232</td>\n","      <td>0.388791</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>2.017143</td>\n","      <td>3.842061</td>\n","      <td>0.093463</td>\n","      <td>0.452189</td>\n","      <td>0.008934</td>\n","      <td>0.134842</td>\n","      <td>2.387391</td>\n","      <td>0.0</td>\n","      <td>0.020204</td>\n","      <td>6.705792</td>\n","      <td>...</td>\n","      <td>0.034522</td>\n","      <td>0.019341</td>\n","      <td>0.019339</td>\n","      <td>2.978324</td>\n","      <td>3.210679</td>\n","      <td>0.029853</td>\n","      <td>0.052316</td>\n","      <td>0.052670</td>\n","      <td>0.102570</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>4.000000</td>\n","      <td>0.000000</td>\n","      <td>2.921928</td>\n","      <td>0.012056</td>\n","      <td>0.305556</td>\n","      <td>8.000000</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>9.000000</td>\n","      <td>...</td>\n","      <td>0.066667</td>\n","      <td>0.888889</td>\n","      <td>0.025000</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>0.000000</td>\n","      <td>0.089459</td>\n","      <td>0.030941</td>\n","      <td>0.099415</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>3.000000</td>\n","      <td>11.000000</td>\n","      <td>0.250000</td>\n","      <td>3.906891</td>\n","      <td>0.029463</td>\n","      <td>0.545455</td>\n","      <td>12.000000</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>16.000000</td>\n","      <td>...</td>\n","      <td>0.129032</td>\n","      <td>0.937500</td>\n","      <td>0.035714</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>0.062500</td>\n","      <td>0.133325</td>\n","      <td>0.078893</td>\n","      <td>0.329670</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>4.000000</td>\n","      <td>13.000000</td>\n","      <td>0.333333</td>\n","      <td>4.247928</td>\n","      <td>0.035977</td>\n","      <td>0.620690</td>\n","      <td>13.000000</td>\n","      <td>0.0</td>\n","      <td>0.514706</td>\n","      <td>20.000000</td>\n","      <td>...</td>\n","      <td>0.156250</td>\n","      <td>0.950000</td>\n","      <td>0.050000</td>\n","      <td>5.000000</td>\n","      <td>6.000000</td>\n","      <td>0.068966</td>\n","      <td>0.170185</td>\n","      <td>0.109683</td>\n","      <td>0.400000</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>5.000000</td>\n","      <td>17.000000</td>\n","      <td>0.375000</td>\n","      <td>4.606739</td>\n","      <td>0.041660</td>\n","      <td>0.750000</td>\n","      <td>15.000000</td>\n","      <td>0.0</td>\n","      <td>0.531250</td>\n","      <td>28.000000</td>\n","      <td>...</td>\n","      <td>0.187500</td>\n","      <td>0.964286</td>\n","      <td>0.062500</td>\n","      <td>9.000000</td>\n","      <td>10.000000</td>\n","      <td>0.100000</td>\n","      <td>0.215801</td>\n","      <td>0.158928</td>\n","      <td>0.463602</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>10.000000</td>\n","      <td>24.000000</td>\n","      <td>0.600000</td>\n","      <td>5.247928</td>\n","      <td>0.063315</td>\n","      <td>0.947368</td>\n","      <td>20.000000</td>\n","      <td>0.0</td>\n","      <td>0.580645</td>\n","      <td>40.000000</td>\n","      <td>...</td>\n","      <td>0.266667</td>\n","      <td>0.975000</td>\n","      <td>0.111111</td>\n","      <td>15.000000</td>\n","      <td>16.000000</td>\n","      <td>0.166667</td>\n","      <td>0.327523</td>\n","      <td>0.336816</td>\n","      <td>0.687831</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 32 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-893313a6-5175-4627-bd4c-af4c60ff967e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-893313a6-5175-4627-bd4c-af4c60ff967e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-893313a6-5175-4627-bd4c-af4c60ff967e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-e3f7fae2-072e-4799-8414-bf82215519b1\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e3f7fae2-072e-4799-8414-bf82215519b1')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-e3f7fae2-072e-4799-8414-bf82215519b1 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe"}},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["#!/usr/bin/env python3\n","\"\"\"\n","Fast CPU-only DGA Feature Extraction (31 features)\n","Input:  domains.csv (must contain a column 'domain')\n","Output: features_optimized.csv\n","\"\"\"\n","\n","import re, math, string, zlib\n","import pandas as pd\n","import numpy as np\n","from collections import Counter\n","from difflib import SequenceMatcher\n","from nltk.corpus import words as nltk_words\n","import nltk\n","\n","try:\n","    nltk.data.find(\"corpora/words\")\n","except LookupError:\n","    nltk.download(\"words\")\n","\n","ENGLISH_WORDS = set(w.lower() for w in nltk_words.words())\n","VOWELS = set(\"aeiou\")\n","CONSONANTS = set(string.ascii_lowercase) - VOWELS\n","ALPHABET = string.ascii_lowercase\n","POP_DOMAINS = [\"google\", \"facebook\", \"youtube\", \"amazon\", \"twitter\", \"instagram\"]\n","\n","# Precompute key maps\n","KEYBOARD_POS = {\n","    c: (i // 10, i % 10)\n","    for i, c in enumerate(\"qwertyuiopasdfghjklzxcvbnm\")\n","}\n","\n","# --- Utility functions ---\n","def safe(s): return str(s).lower() if isinstance(s, str) else \"\"\n","\n","def shannon_entropy(s):\n","    if not s: return 0.0\n","    freq = Counter(s)\n","    probs = np.array(list(freq.values()), dtype=float) / len(s)\n","    return -np.sum(probs * np.log2(probs + 1e-12))\n","\n","def renyi_entropy(s, alpha=2):\n","    if not s: return 0.0\n","    freq = Counter(s)\n","    probs = np.array(list(freq.values()), dtype=float) / len(s)\n","    return 1.0 / (1.0 - alpha) * np.log2(np.sum(probs ** alpha) + 1e-12)\n","\n","def kolmogorov_complexity(s):\n","    if not s: return 0.0\n","    comp = zlib.compress(s.encode(\"utf-8\"))\n","    return len(comp) / max(1, len(s))\n","\n","def bigram_likelihood(s):\n","    if len(s) < 2: return 0.0\n","    bigrams = [s[i:i+2] for i in range(len(s)-1)]\n","    freq = Counter(bigrams)\n","    probs = np.array(list(freq.values())) / len(bigrams)\n","    return -np.sum(probs * np.log2(probs + 1e-12))\n","\n","def trigram_score(s):\n","    if len(s) < 3: return 0.0\n","    trigrams = [s[i:i+3] for i in range(len(s)-2)]\n","    freq = Counter(trigrams)\n","    probs = np.array(list(freq.values())) / len(trigrams)\n","    return -np.sum(probs * np.log2(probs + 1e-12))\n","\n","def char_freq_dev(s):\n","    if not s: return 0.0\n","    freq = np.array(list(Counter(s).values()))\n","    return np.std(freq / np.sum(freq))\n","\n","def char_gini(s):\n","    if not s: return 0.0\n","    freq = np.array(list(Counter(s).values()), dtype=float)\n","    p = freq / freq.sum()\n","    return 1.0 - np.sum(p**2)\n","\n","def vowel_consonant_features(s):\n","    v_runs = re.findall(r\"[aeiou]+\", s)\n","    c_runs = re.findall(r\"[bcdfghjklmnpqrstvwxyz]+\", s)\n","    v_run_count = len(v_runs)\n","    c_run_count = len(c_runs)\n","    v_cluster_ratio = max((len(r) for r in v_runs), default=0) / max(1, len(s))\n","    return v_run_count, c_run_count, v_cluster_ratio\n","\n","def max_consonant_cluster(s):\n","    clusters = re.findall(r\"[bcdfghjklmnpqrstvwxyz]+\", s)\n","    return max((len(c) for c in clusters), default=0)\n","\n","def pronounceability_score(s):\n","    if not s: return 0.0\n","    score = sum(c in VOWELS for c in s) / len(s)\n","    return score\n","\n","def unique_char_ratio(s):\n","    return len(set(s)) / max(1, len(s))\n","\n","def unique_char(s):\n","    return len(set(s))\n","\n","def dict_std(s):\n","    if not s: return 0.0\n","    words_found = sum(w in ENGLISH_WORDS for w in re.findall(r\"[a-z]+\", s))\n","    return words_found / max(1, len(s.split(\".\")))\n","\n","def markov_chain_likelihood(s):\n","    if len(s) < 2: return 0.0\n","    probs = []\n","    for i in range(1, len(s)):\n","        probs.append(1.0 if s[i] == s[i-1] else 0.5)\n","    return np.mean(probs)\n","\n","def kl_divergence(s):\n","    benign_dist = np.ones(26) / 26\n","    if not s: return 0.0\n","    counts = np.array([s.count(c) for c in ALPHABET], dtype=float)\n","    if counts.sum() == 0: return 0.0\n","    p = counts / counts.sum()\n","    return np.sum(p * np.log2((p + 1e-12) / (benign_dist + 1e-12)))\n","\n","def sliding_word_ratio(s):\n","    if len(s) < 4: return 0.0\n","    matches = sum(s[i:i+4] in ENGLISH_WORDS for i in range(len(s)-3))\n","    return matches / (len(s) - 3)\n","\n","def keyboard_distance_score(s):\n","    total = 0.0\n","    count = 0\n","    for a, b in zip(s, s[1:]):\n","        if a in KEYBOARD_POS and b in KEYBOARD_POS:\n","            pa, pb = KEYBOARD_POS[a], KEYBOARD_POS[b]\n","            total += math.dist(pa, pb)\n","            count += 1\n","    return total / count if count else 0.0\n","\n","def min_levenshtein_to_popular(s):\n","    return min(SequenceMatcher(None, s, p).ratio() for p in POP_DOMAINS)\n","\n","def repetition_ratio(s):\n","    if not s: return 0.0\n","    freq = Counter(s)\n","    return max(freq.values()) / len(s)\n","\n","def alphabetic_ratio(s):\n","    letters = sum(c.isalpha() for c in s)\n","    return letters / max(1, len(s))\n","\n","def symbol_ratio(s):\n","    symbols = sum(not c.isalnum() for c in s)\n","    return symbols / max(1, len(s))\n","\n","def entropy_per_length(s):\n","    e = shannon_entropy(s)\n","    return e / max(1, len(s))\n","\n","def entropy_slope(s):\n","    if len(s) < 2: return 0.0\n","    entropies = [shannon_entropy(s[:i]) for i in range(2, len(s)+1)]\n","    x = np.arange(2, len(s)+1)\n","    slope, _ = np.polyfit(x, entropies, 1)\n","    return slope\n","\n","def char_distribution_symmetry(s):\n","    if not s: return 0.0\n","    freq = np.array(list(Counter(s).values()), dtype=float)\n","    mean = freq.mean()\n","    return np.mean(np.abs(freq - mean)) / mean\n","\n","# === MAIN ===\n","def main(input_csv=\"ndga_version2.csv\", output_csv=\"oct30_ndga_v1.csv\"):\n","    df = pd.read_csv(input_csv, dtype=str)\n","    domains = df[\"domain\"].fillna(\"\").str.lower().tolist()\n","    print(f\"Processing {len(domains)} domains...\")\n","\n","    feats = []\n","    for d in domains:\n","        s = safe(d)\n","        v_run, c_run, v_ratio = vowel_consonant_features(s)\n","        feats.append({\n","            \"Maximum_Consonants_Cluster\": max_consonant_cluster(s),\n","            \"Consonant_count\": sum(c in CONSONANTS for c in s),\n","            \"Pronounceability_Score\": pronounceability_score(s),\n","            \"Bigram-Likelihood\": bigram_likelihood(s),\n","            \"Character_Frequency_Deviation\": char_freq_dev(s),\n","            \"Unique_Character_Ratio\": unique_char_ratio(s),\n","            \"Unique_Character\": unique_char(s),\n","            \"Dictionary_Standard\": dict_std(s),\n","            \"Markov_Chain_Likelihood\": markov_chain_likelihood(s),\n","            \"Length\": len(s),\n","            \"Compression_Ratio\": kolmogorov_complexity(s),\n","            \"Bigram_Score\": bigram_likelihood(s),\n","            \"Trigram_Score\": trigram_score(s),\n","            \"N-gram_LM_perplexity\": bigram_likelihood(s) + trigram_score(s),\n","            \"Normal_Character_Frequency_varience\": char_freq_dev(s),\n","            \"Character_Gini\": char_gini(s),\n","            \"KL_Divergence\": kl_divergence(s),\n","            \"Sliding_word_ratio\": sliding_word_ratio(s),\n","            \"Kolmogorov_Complexity\": kolmogorov_complexity(s),\n","            \"Renyi_Entropy\": renyi_entropy(s),\n","            \"Keyboard_Distance_Score\": keyboard_distance_score(s),\n","            \"Min_Levenshtein_To_Popular\": min_levenshtein_to_popular(s),\n","            \"Repetition_Ratio\": repetition_ratio(s),\n","            \"Alphabetic_Ratio\": alphabetic_ratio(s),\n","            \"Symbol_Ratio\": symbol_ratio(s),\n","            \"Vowel_run_count\": v_run,\n","            \"Consonant_run_count\": c_run,\n","            \"Vowel_cluster_ratio\": v_ratio,\n","            \"Entropy_per_length\": entropy_per_length(s),\n","            \"Entropy_Slope\": entropy_slope(s),\n","            \"Character_Distribution_Symmetry\": char_distribution_symmetry(s),\n","        })\n","\n","    feat_df = pd.DataFrame(feats)\n","    out = pd.concat([df, feat_df], axis=1)\n","    out.to_csv(output_csv, index=False)\n","    print(f\"✅ Features saved to {output_csv}\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0xEIkYfcjiQS","executionInfo":{"status":"ok","timestamp":1761819797090,"user_tz":-330,"elapsed":1041808,"user":{"displayName":"Manoj M J","userId":"05788064290666556527"}},"outputId":"4f8acd5c-8dda-41dd-b7a7-f2e0d0b0bc2f"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing 1000018 domains...\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1863040856.py:160: RankWarning: Polyfit may be poorly conditioned\n","  slope, _ = np.polyfit(x, entropies, 1)\n"]},{"output_type":"stream","name":"stdout","text":["✅ Features saved to oct30_ndga_v1.csv\n"]}]},{"cell_type":"code","source":["df=pd.read_csv('oct30_ndga_v1.csv')\n","df.describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"id":"SIKS0xFFku1V","executionInfo":{"status":"ok","timestamp":1761819861225,"user_tz":-330,"elapsed":7213,"user":{"displayName":"Manoj M J","userId":"05788064290666556527"}},"outputId":"08fe55cd-6ac7-4ced-95ab-64c56d20853d"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           label  Maximum_Consonants_Cluster  Consonant_count  \\\n","count  1000018.0                1.000018e+06     1.000018e+06   \n","mean         0.0                2.559998e+00     7.716392e+00   \n","std          0.0                1.070682e+00     2.782675e+00   \n","min          0.0                0.000000e+00     0.000000e+00   \n","25%          0.0                2.000000e+00     6.000000e+00   \n","50%          0.0                2.000000e+00     7.000000e+00   \n","75%          0.0                3.000000e+00     9.000000e+00   \n","max          0.0                4.300000e+01     4.500000e+01   \n","\n","       Pronounceability_Score  Bigram-Likelihood  \\\n","count            1.000018e+06       1.000018e+06   \n","mean             3.146914e-01       3.526768e+00   \n","std              9.763058e-02       4.773525e-01   \n","min              0.000000e+00      -1.442823e-12   \n","25%              2.666667e-01       3.169925e+00   \n","50%              3.333333e-01       3.546594e+00   \n","75%              3.750000e-01       3.875000e+00   \n","max              8.750000e-01       6.044394e+00   \n","\n","       Character_Frequency_Deviation  Unique_Character_Ratio  \\\n","count                   1.000018e+06            1.000018e+06   \n","mean                    3.664792e-02            7.842040e-01   \n","std                     1.793356e-02            1.191128e-01   \n","min                     0.000000e+00            4.347826e-02   \n","25%                     2.886751e-02            7.000000e-01   \n","50%                     3.586096e-02            7.857143e-01   \n","75%                     4.404110e-02            8.750000e-01   \n","max                     4.782609e-01            1.000000e+00   \n","\n","       Unique_Character  Dictionary_Standard  Markov_Chain_Likelihood  ...  \\\n","count      1.000018e+06         1.000018e+06             1.000018e+06  ...   \n","mean       1.027084e+01         2.110617e-01             5.115228e-01  ...   \n","std        2.394362e+00         3.294658e-01             2.439352e-02  ...   \n","min        2.000000e+00         0.000000e+00             5.000000e-01  ...   \n","25%        9.000000e+00         0.000000e+00             5.000000e-01  ...   \n","50%        1.000000e+01         0.000000e+00             5.000000e-01  ...   \n","75%        1.200000e+01         5.000000e-01             5.000000e-01  ...   \n","max        3.700000e+01         8.500000e+00             9.777778e-01  ...   \n","\n","       Min_Levenshtein_To_Popular  Repetition_Ratio  Alphabetic_Ratio  \\\n","count                1.000018e+06      1.000018e+06      1.000018e+06   \n","mean                 9.522608e-02      1.833156e-01      8.837410e-01   \n","std                  4.453127e-02      5.519978e-02      8.710253e-02   \n","min                  0.000000e+00      4.477612e-02      1.176471e-01   \n","25%                  8.333333e-02      1.428571e-01      8.750000e-01   \n","50%                  1.000000e-01      1.764706e-01      9.090909e-01   \n","75%                  1.176471e-01      2.142857e-01      9.285714e-01   \n","max                  3.157895e-01      9.782609e-01      1.000000e+00   \n","\n","       Symbol_Ratio  Vowel_run_count  Consonant_run_count  \\\n","count  1.000018e+06     1.000018e+06         1.000018e+06   \n","mean   9.447994e-02     3.886544e+00         5.200499e+00   \n","std    3.649864e-02     1.761619e+00         1.833195e+00   \n","min    0.000000e+00     0.000000e+00         0.000000e+00   \n","25%    6.666667e-02     3.000000e+00         4.000000e+00   \n","50%    8.695652e-02     4.000000e+00         5.000000e+00   \n","75%    1.111111e-01     5.000000e+00         6.000000e+00   \n","max    5.600000e-01     2.500000e+01         2.500000e+01   \n","\n","       Vowel_cluster_ratio  Entropy_per_length  Entropy_Slope  \\\n","count         1.000018e+06        1.000018e+06   1.000018e+06   \n","mean          1.085705e-01        2.555062e-01   1.958674e-01   \n","std           4.979761e-02        5.937606e-02   6.539805e-02   \n","min           0.000000e+00        3.284717e-03  -9.436094e-02   \n","25%           7.692308e-02        2.127573e-01   1.485760e-01   \n","50%           1.000000e-01        2.515458e-01   1.880979e-01   \n","75%           1.333333e-01        2.921928e-01   2.348486e-01   \n","max           7.692308e-01        5.000000e-01   6.347488e-01   \n","\n","       Character_Distribution_Symmetry  \n","count                     1.000018e+06  \n","mean                      2.922898e-01  \n","std                       1.290987e-01  \n","min                       0.000000e+00  \n","25%                       2.142857e-01  \n","50%                       3.174603e-01  \n","75%                       3.850267e-01  \n","max                       1.213930e+00  \n","\n","[8 rows x 32 columns]"],"text/html":["\n","  <div id=\"df-7b9cdbe8-f522-4323-8721-263d51fa2403\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>Maximum_Consonants_Cluster</th>\n","      <th>Consonant_count</th>\n","      <th>Pronounceability_Score</th>\n","      <th>Bigram-Likelihood</th>\n","      <th>Character_Frequency_Deviation</th>\n","      <th>Unique_Character_Ratio</th>\n","      <th>Unique_Character</th>\n","      <th>Dictionary_Standard</th>\n","      <th>Markov_Chain_Likelihood</th>\n","      <th>...</th>\n","      <th>Min_Levenshtein_To_Popular</th>\n","      <th>Repetition_Ratio</th>\n","      <th>Alphabetic_Ratio</th>\n","      <th>Symbol_Ratio</th>\n","      <th>Vowel_run_count</th>\n","      <th>Consonant_run_count</th>\n","      <th>Vowel_cluster_ratio</th>\n","      <th>Entropy_per_length</th>\n","      <th>Entropy_Slope</th>\n","      <th>Character_Distribution_Symmetry</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1000018.0</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>...</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.0</td>\n","      <td>2.559998e+00</td>\n","      <td>7.716392e+00</td>\n","      <td>3.146914e-01</td>\n","      <td>3.526768e+00</td>\n","      <td>3.664792e-02</td>\n","      <td>7.842040e-01</td>\n","      <td>1.027084e+01</td>\n","      <td>2.110617e-01</td>\n","      <td>5.115228e-01</td>\n","      <td>...</td>\n","      <td>9.522608e-02</td>\n","      <td>1.833156e-01</td>\n","      <td>8.837410e-01</td>\n","      <td>9.447994e-02</td>\n","      <td>3.886544e+00</td>\n","      <td>5.200499e+00</td>\n","      <td>1.085705e-01</td>\n","      <td>2.555062e-01</td>\n","      <td>1.958674e-01</td>\n","      <td>2.922898e-01</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.0</td>\n","      <td>1.070682e+00</td>\n","      <td>2.782675e+00</td>\n","      <td>9.763058e-02</td>\n","      <td>4.773525e-01</td>\n","      <td>1.793356e-02</td>\n","      <td>1.191128e-01</td>\n","      <td>2.394362e+00</td>\n","      <td>3.294658e-01</td>\n","      <td>2.439352e-02</td>\n","      <td>...</td>\n","      <td>4.453127e-02</td>\n","      <td>5.519978e-02</td>\n","      <td>8.710253e-02</td>\n","      <td>3.649864e-02</td>\n","      <td>1.761619e+00</td>\n","      <td>1.833195e+00</td>\n","      <td>4.979761e-02</td>\n","      <td>5.937606e-02</td>\n","      <td>6.539805e-02</td>\n","      <td>1.290987e-01</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.0</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>-1.442823e-12</td>\n","      <td>0.000000e+00</td>\n","      <td>4.347826e-02</td>\n","      <td>2.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>5.000000e-01</td>\n","      <td>...</td>\n","      <td>0.000000e+00</td>\n","      <td>4.477612e-02</td>\n","      <td>1.176471e-01</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>3.284717e-03</td>\n","      <td>-9.436094e-02</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.0</td>\n","      <td>2.000000e+00</td>\n","      <td>6.000000e+00</td>\n","      <td>2.666667e-01</td>\n","      <td>3.169925e+00</td>\n","      <td>2.886751e-02</td>\n","      <td>7.000000e-01</td>\n","      <td>9.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>5.000000e-01</td>\n","      <td>...</td>\n","      <td>8.333333e-02</td>\n","      <td>1.428571e-01</td>\n","      <td>8.750000e-01</td>\n","      <td>6.666667e-02</td>\n","      <td>3.000000e+00</td>\n","      <td>4.000000e+00</td>\n","      <td>7.692308e-02</td>\n","      <td>2.127573e-01</td>\n","      <td>1.485760e-01</td>\n","      <td>2.142857e-01</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.0</td>\n","      <td>2.000000e+00</td>\n","      <td>7.000000e+00</td>\n","      <td>3.333333e-01</td>\n","      <td>3.546594e+00</td>\n","      <td>3.586096e-02</td>\n","      <td>7.857143e-01</td>\n","      <td>1.000000e+01</td>\n","      <td>0.000000e+00</td>\n","      <td>5.000000e-01</td>\n","      <td>...</td>\n","      <td>1.000000e-01</td>\n","      <td>1.764706e-01</td>\n","      <td>9.090909e-01</td>\n","      <td>8.695652e-02</td>\n","      <td>4.000000e+00</td>\n","      <td>5.000000e+00</td>\n","      <td>1.000000e-01</td>\n","      <td>2.515458e-01</td>\n","      <td>1.880979e-01</td>\n","      <td>3.174603e-01</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.0</td>\n","      <td>3.000000e+00</td>\n","      <td>9.000000e+00</td>\n","      <td>3.750000e-01</td>\n","      <td>3.875000e+00</td>\n","      <td>4.404110e-02</td>\n","      <td>8.750000e-01</td>\n","      <td>1.200000e+01</td>\n","      <td>5.000000e-01</td>\n","      <td>5.000000e-01</td>\n","      <td>...</td>\n","      <td>1.176471e-01</td>\n","      <td>2.142857e-01</td>\n","      <td>9.285714e-01</td>\n","      <td>1.111111e-01</td>\n","      <td>5.000000e+00</td>\n","      <td>6.000000e+00</td>\n","      <td>1.333333e-01</td>\n","      <td>2.921928e-01</td>\n","      <td>2.348486e-01</td>\n","      <td>3.850267e-01</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.0</td>\n","      <td>4.300000e+01</td>\n","      <td>4.500000e+01</td>\n","      <td>8.750000e-01</td>\n","      <td>6.044394e+00</td>\n","      <td>4.782609e-01</td>\n","      <td>1.000000e+00</td>\n","      <td>3.700000e+01</td>\n","      <td>8.500000e+00</td>\n","      <td>9.777778e-01</td>\n","      <td>...</td>\n","      <td>3.157895e-01</td>\n","      <td>9.782609e-01</td>\n","      <td>1.000000e+00</td>\n","      <td>5.600000e-01</td>\n","      <td>2.500000e+01</td>\n","      <td>2.500000e+01</td>\n","      <td>7.692308e-01</td>\n","      <td>5.000000e-01</td>\n","      <td>6.347488e-01</td>\n","      <td>1.213930e+00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 32 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b9cdbe8-f522-4323-8721-263d51fa2403')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7b9cdbe8-f522-4323-8721-263d51fa2403 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7b9cdbe8-f522-4323-8721-263d51fa2403');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-bdbd3c1b-39bc-4a0a-b7e5-0301171f6a69\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bdbd3c1b-39bc-4a0a-b7e5-0301171f6a69')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-bdbd3c1b-39bc-4a0a-b7e5-0301171f6a69 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["import pandas as pd\n","\n","def reorder_columns(input_csv, output_csv, desired_order):\n","    \"\"\"\n","    Reorder the columns of a CSV file based on user-defined order.\n","\n","    Parameters:\n","    - input_csv (str): Path to input CSV file.\n","    - output_csv (str): Path to output CSV file with reordered columns.\n","    - desired_order (list): List of column names in the desired order.\n","    \"\"\"\n","    # Load dataset\n","    df = pd.read_csv(input_csv)\n","\n","    # Check which desired columns exist\n","    available_columns = [col for col in desired_order if col in df.columns]\n","\n","    # Add missing columns (if any were not in df)\n","    missing_columns = [col for col in desired_order if col not in df.columns]\n","    for col in missing_columns:\n","        df[col] = None  # Fill with None or default values\n","\n","    # Reorder\n","    df = df[available_columns + [col for col in df.columns if col not in available_columns]]\n","\n","    # Save output\n","    df.to_csv(output_csv, index=False)\n","    print(f\"✅ Reordered CSV saved as {output_csv}\")\n","\n","\n","# =====================\n","# Example usage\n","# =====================\n","\n","# Suppose your dataset has 58 features + \"domain\" + \"label\"\n","input_csv = \"oct30_ndga_v1.csv\"\n","output_csv = \"oct30_ndga_v2.csv\"\n","\n","# User-defined column order (just an example)\n","desired_order = [\n","\n","\n","\n","\n","\n","\"domain\",\n","\"Maximum_Consonants_Cluster\",\n","\"Consonant_count\",\n","\"Pronounceability_Score\",\n","\"Bigram-Likelihood\",\n","\"Character_Frequency_Deviation\",\n","\"Unique_Character_Ratio\",\n","\"Unique_Character\",\n","\"Dictionary_Standard\",\n","\"Markov_Chain_Likelihood\",\n","\"Length\",\n","\"Compression_Ratio\",\n","\"Bigram_Score\",\n","\"Trigram_Score\",\n","\"N-gram_LM_perplexity\",\n","\"Normal_Character_Frequency_varience\",\n","\"Character_Gini\",\n","\"KL_Divergence\",\n","\"Sliding_word_ratio\",\n","\"Kolmogorov_Complexity\",\n","\"Renyi_Entropy\",\n","\"Keyboard_Distance_Score\",\n","\"Min_Levenshtein_To_Popular\",\n","\"Repetition_Ratio\",\n","\"Alphabetic_Ratio\",\n","\"Symbol_Ratio\",\n","\"Vowel_run_count\",\n","\"Consonant_run_count\",\n","\"Vowel_cluster_ratio\",\n","\"Entropy_per_length\",\n","\"Entropy_Slope\",\n","\"Character_Distribution_Symmetry\",\n","\"label\"\n","\n","]\n","\n","# Reorder dataset\n","reorder_columns(input_csv, output_csv, desired_order)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"76syvBMZnN5M","executionInfo":{"status":"ok","timestamp":1761819967957,"user_tz":-330,"elapsed":54897,"user":{"displayName":"Manoj M J","userId":"05788064290666556527"}},"outputId":"a4659470-2af0-4e17-f676-d421af67755e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Reordered CSV saved as oct30_ndga_v2.csv\n"]}]},{"cell_type":"code","source":["\n","df=pd.read_csv('oct30_ndga_v2.csv')\n","df.describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"id":"OEOBqTGmnwSK","executionInfo":{"status":"ok","timestamp":1761819986437,"user_tz":-330,"elapsed":8084,"user":{"displayName":"Manoj M J","userId":"05788064290666556527"}},"outputId":"4133417a-b226-48bf-97b8-6397686342e6"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Maximum_Consonants_Cluster  Consonant_count  Pronounceability_Score  \\\n","count                1.000018e+06     1.000018e+06            1.000018e+06   \n","mean                 2.559998e+00     7.716392e+00            3.146914e-01   \n","std                  1.070682e+00     2.782675e+00            9.763058e-02   \n","min                  0.000000e+00     0.000000e+00            0.000000e+00   \n","25%                  2.000000e+00     6.000000e+00            2.666667e-01   \n","50%                  2.000000e+00     7.000000e+00            3.333333e-01   \n","75%                  3.000000e+00     9.000000e+00            3.750000e-01   \n","max                  4.300000e+01     4.500000e+01            8.750000e-01   \n","\n","       Bigram-Likelihood  Character_Frequency_Deviation  \\\n","count       1.000018e+06                   1.000018e+06   \n","mean        3.526768e+00                   3.664792e-02   \n","std         4.773525e-01                   1.793356e-02   \n","min        -1.442823e-12                   0.000000e+00   \n","25%         3.169925e+00                   2.886751e-02   \n","50%         3.546594e+00                   3.586096e-02   \n","75%         3.875000e+00                   4.404110e-02   \n","max         6.044394e+00                   4.782609e-01   \n","\n","       Unique_Character_Ratio  Unique_Character  Dictionary_Standard  \\\n","count            1.000018e+06      1.000018e+06         1.000018e+06   \n","mean             7.842040e-01      1.027084e+01         2.110617e-01   \n","std              1.191128e-01      2.394362e+00         3.294658e-01   \n","min              4.347826e-02      2.000000e+00         0.000000e+00   \n","25%              7.000000e-01      9.000000e+00         0.000000e+00   \n","50%              7.857143e-01      1.000000e+01         0.000000e+00   \n","75%              8.750000e-01      1.200000e+01         5.000000e-01   \n","max              1.000000e+00      3.700000e+01         8.500000e+00   \n","\n","       Markov_Chain_Likelihood        Length  ...  Repetition_Ratio  \\\n","count             1.000018e+06  1.000018e+06  ...      1.000018e+06   \n","mean              5.115228e-01  1.352508e+01  ...      1.833156e-01   \n","std               2.439352e-02  4.305555e+00  ...      5.519978e-02   \n","min               5.000000e-01  2.000000e+00  ...      4.477612e-02   \n","25%               5.000000e-01  1.000000e+01  ...      1.428571e-01   \n","50%               5.000000e-01  1.300000e+01  ...      1.764706e-01   \n","75%               5.000000e-01  1.600000e+01  ...      2.142857e-01   \n","max               9.777778e-01  7.500000e+01  ...      9.782609e-01   \n","\n","       Alphabetic_Ratio  Symbol_Ratio  Vowel_run_count  Consonant_run_count  \\\n","count      1.000018e+06  1.000018e+06     1.000018e+06         1.000018e+06   \n","mean       8.837410e-01  9.447994e-02     3.886544e+00         5.200499e+00   \n","std        8.710253e-02  3.649864e-02     1.761619e+00         1.833195e+00   \n","min        1.176471e-01  0.000000e+00     0.000000e+00         0.000000e+00   \n","25%        8.750000e-01  6.666667e-02     3.000000e+00         4.000000e+00   \n","50%        9.090909e-01  8.695652e-02     4.000000e+00         5.000000e+00   \n","75%        9.285714e-01  1.111111e-01     5.000000e+00         6.000000e+00   \n","max        1.000000e+00  5.600000e-01     2.500000e+01         2.500000e+01   \n","\n","       Vowel_cluster_ratio  Entropy_per_length  Entropy_Slope  \\\n","count         1.000018e+06        1.000018e+06   1.000018e+06   \n","mean          1.085705e-01        2.555062e-01   1.958674e-01   \n","std           4.979761e-02        5.937606e-02   6.539805e-02   \n","min           0.000000e+00        3.284717e-03  -9.436094e-02   \n","25%           7.692308e-02        2.127573e-01   1.485760e-01   \n","50%           1.000000e-01        2.515458e-01   1.880979e-01   \n","75%           1.333333e-01        2.921928e-01   2.348486e-01   \n","max           7.692308e-01        5.000000e-01   6.347488e-01   \n","\n","       Character_Distribution_Symmetry      label  \n","count                     1.000018e+06  1000018.0  \n","mean                      2.922898e-01        0.0  \n","std                       1.290987e-01        0.0  \n","min                       0.000000e+00        0.0  \n","25%                       2.142857e-01        0.0  \n","50%                       3.174603e-01        0.0  \n","75%                       3.850267e-01        0.0  \n","max                       1.213930e+00        0.0  \n","\n","[8 rows x 32 columns]"],"text/html":["\n","  <div id=\"df-65ca1af3-5e74-430b-a123-bb64c8504733\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Maximum_Consonants_Cluster</th>\n","      <th>Consonant_count</th>\n","      <th>Pronounceability_Score</th>\n","      <th>Bigram-Likelihood</th>\n","      <th>Character_Frequency_Deviation</th>\n","      <th>Unique_Character_Ratio</th>\n","      <th>Unique_Character</th>\n","      <th>Dictionary_Standard</th>\n","      <th>Markov_Chain_Likelihood</th>\n","      <th>Length</th>\n","      <th>...</th>\n","      <th>Repetition_Ratio</th>\n","      <th>Alphabetic_Ratio</th>\n","      <th>Symbol_Ratio</th>\n","      <th>Vowel_run_count</th>\n","      <th>Consonant_run_count</th>\n","      <th>Vowel_cluster_ratio</th>\n","      <th>Entropy_per_length</th>\n","      <th>Entropy_Slope</th>\n","      <th>Character_Distribution_Symmetry</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>...</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1.000018e+06</td>\n","      <td>1000018.0</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>2.559998e+00</td>\n","      <td>7.716392e+00</td>\n","      <td>3.146914e-01</td>\n","      <td>3.526768e+00</td>\n","      <td>3.664792e-02</td>\n","      <td>7.842040e-01</td>\n","      <td>1.027084e+01</td>\n","      <td>2.110617e-01</td>\n","      <td>5.115228e-01</td>\n","      <td>1.352508e+01</td>\n","      <td>...</td>\n","      <td>1.833156e-01</td>\n","      <td>8.837410e-01</td>\n","      <td>9.447994e-02</td>\n","      <td>3.886544e+00</td>\n","      <td>5.200499e+00</td>\n","      <td>1.085705e-01</td>\n","      <td>2.555062e-01</td>\n","      <td>1.958674e-01</td>\n","      <td>2.922898e-01</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>1.070682e+00</td>\n","      <td>2.782675e+00</td>\n","      <td>9.763058e-02</td>\n","      <td>4.773525e-01</td>\n","      <td>1.793356e-02</td>\n","      <td>1.191128e-01</td>\n","      <td>2.394362e+00</td>\n","      <td>3.294658e-01</td>\n","      <td>2.439352e-02</td>\n","      <td>4.305555e+00</td>\n","      <td>...</td>\n","      <td>5.519978e-02</td>\n","      <td>8.710253e-02</td>\n","      <td>3.649864e-02</td>\n","      <td>1.761619e+00</td>\n","      <td>1.833195e+00</td>\n","      <td>4.979761e-02</td>\n","      <td>5.937606e-02</td>\n","      <td>6.539805e-02</td>\n","      <td>1.290987e-01</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>-1.442823e-12</td>\n","      <td>0.000000e+00</td>\n","      <td>4.347826e-02</td>\n","      <td>2.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>5.000000e-01</td>\n","      <td>2.000000e+00</td>\n","      <td>...</td>\n","      <td>4.477612e-02</td>\n","      <td>1.176471e-01</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>3.284717e-03</td>\n","      <td>-9.436094e-02</td>\n","      <td>0.000000e+00</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>2.000000e+00</td>\n","      <td>6.000000e+00</td>\n","      <td>2.666667e-01</td>\n","      <td>3.169925e+00</td>\n","      <td>2.886751e-02</td>\n","      <td>7.000000e-01</td>\n","      <td>9.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>5.000000e-01</td>\n","      <td>1.000000e+01</td>\n","      <td>...</td>\n","      <td>1.428571e-01</td>\n","      <td>8.750000e-01</td>\n","      <td>6.666667e-02</td>\n","      <td>3.000000e+00</td>\n","      <td>4.000000e+00</td>\n","      <td>7.692308e-02</td>\n","      <td>2.127573e-01</td>\n","      <td>1.485760e-01</td>\n","      <td>2.142857e-01</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>2.000000e+00</td>\n","      <td>7.000000e+00</td>\n","      <td>3.333333e-01</td>\n","      <td>3.546594e+00</td>\n","      <td>3.586096e-02</td>\n","      <td>7.857143e-01</td>\n","      <td>1.000000e+01</td>\n","      <td>0.000000e+00</td>\n","      <td>5.000000e-01</td>\n","      <td>1.300000e+01</td>\n","      <td>...</td>\n","      <td>1.764706e-01</td>\n","      <td>9.090909e-01</td>\n","      <td>8.695652e-02</td>\n","      <td>4.000000e+00</td>\n","      <td>5.000000e+00</td>\n","      <td>1.000000e-01</td>\n","      <td>2.515458e-01</td>\n","      <td>1.880979e-01</td>\n","      <td>3.174603e-01</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>3.000000e+00</td>\n","      <td>9.000000e+00</td>\n","      <td>3.750000e-01</td>\n","      <td>3.875000e+00</td>\n","      <td>4.404110e-02</td>\n","      <td>8.750000e-01</td>\n","      <td>1.200000e+01</td>\n","      <td>5.000000e-01</td>\n","      <td>5.000000e-01</td>\n","      <td>1.600000e+01</td>\n","      <td>...</td>\n","      <td>2.142857e-01</td>\n","      <td>9.285714e-01</td>\n","      <td>1.111111e-01</td>\n","      <td>5.000000e+00</td>\n","      <td>6.000000e+00</td>\n","      <td>1.333333e-01</td>\n","      <td>2.921928e-01</td>\n","      <td>2.348486e-01</td>\n","      <td>3.850267e-01</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>4.300000e+01</td>\n","      <td>4.500000e+01</td>\n","      <td>8.750000e-01</td>\n","      <td>6.044394e+00</td>\n","      <td>4.782609e-01</td>\n","      <td>1.000000e+00</td>\n","      <td>3.700000e+01</td>\n","      <td>8.500000e+00</td>\n","      <td>9.777778e-01</td>\n","      <td>7.500000e+01</td>\n","      <td>...</td>\n","      <td>9.782609e-01</td>\n","      <td>1.000000e+00</td>\n","      <td>5.600000e-01</td>\n","      <td>2.500000e+01</td>\n","      <td>2.500000e+01</td>\n","      <td>7.692308e-01</td>\n","      <td>5.000000e-01</td>\n","      <td>6.347488e-01</td>\n","      <td>1.213930e+00</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 32 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65ca1af3-5e74-430b-a123-bb64c8504733')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-65ca1af3-5e74-430b-a123-bb64c8504733 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-65ca1af3-5e74-430b-a123-bb64c8504733');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-3f82fe2e-2e5b-4208-bd2e-78fda94daba8\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3f82fe2e-2e5b-4208-bd2e-78fda94daba8')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-3f82fe2e-2e5b-4208-bd2e-78fda94daba8 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe"}},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["import pandas as pd\n","\n","def filter_outliers(df, feature_cols, method=\"iqr\", z_thresh=3, save_path=None):\n","    \"\"\"\n","    Filters datapoints outside the lower/upper bound for each feature\n","    and optionally saves the datapoints that are within the bounds.\n","\n","    Parameters:\n","    -----------\n","    df : pd.DataFrame\n","        Input dataset with features.\n","    feature_cols : list\n","        List of feature columns to check.\n","    method : str\n","        \"iqr\" (default) -> Interquartile Range method\n","        \"zscore\" -> Standard deviation based\n","    z_thresh : int\n","        Threshold for zscore method\n","    save_path : str or None\n","        If provided, saves the filtered dataset to this CSV path.\n","\n","    Returns:\n","    --------\n","    pd.DataFrame : Filtered dataset (within bounds)\n","    pd.DataFrame : Bounds for each feature\n","    \"\"\"\n","    bounds = {}\n","    df_filtered = df.copy()\n","\n","    for col in feature_cols:\n","        if col not in df.columns:\n","            continue  # skip missing features\n","\n","        series = df[col].dropna()\n","\n","        if method == \"iqr\":\n","            Q1 = series.quantile(0.25)\n","            Q3 = series.quantile(0.75)\n","            IQR = Q3 - Q1\n","            lower = Q1 - 1.5 * IQR\n","            upper = Q3 + 1.5 * IQR\n","\n","        elif method == \"zscore\":\n","            mean = series.mean()\n","            std = series.std()\n","            lower = mean - z_thresh * std\n","            upper = mean + z_thresh * std\n","\n","        else:\n","            raise ValueError(\"Method must be 'iqr' or 'zscore'\")\n","\n","        bounds[col] = (lower, upper)\n","\n","        # keep only rows within bounds\n","        df_filtered = df_filtered[(df_filtered[col] >= lower) & (df_filtered[col] <= upper)]\n","\n","    bounds_df = pd.DataFrame(bounds, index=[\"Lower_Bound\", \"Upper_Bound\"]).T\n","\n","    # Save filtered dataset if save_path provided\n","    if save_path:\n","        df_filtered.to_csv(save_path, index=False)\n","        print(f\"✅ Filtered dataset (within bounds) saved to {save_path}\")\n","\n","    return df_filtered.reset_index(drop=True), bounds_df\n","\n","\n","# ==== Example Usage ====\n","all_features = [\n","\n","\"Maximum_Consonants_Cluster\",\n","\"Consonant_count\",\n","\"Pronounceability_Score\",\n","\"Bigram-Likelihood\",\n","\"Character_Frequency_Deviation\",\n","\"Unique_Character_Ratio\",\n","\"Unique_Character\",\n","\"Dictionary_Standard\",\n","\"Markov_Chain_Likelihood\",\n","\"Length\",\n","\"Compression_Ratio\",\n","\"Bigram_Score\",\n","\"Trigram_Score\",\n","\"N-gram_LM_perplexity\",\n","\"Normal_Character_Frequency_varience\",\n","\"Character_Gini\",\n","\"KL_Divergence\",\n","\"Sliding_word_ratio\",\n","\"Kolmogorov_Complexity\",\n","\"Renyi_Entropy\",\n","\"Keyboard_Distance_Score\",\n","\"Min_Levenshtein_To_Popular\",\n","\"Repetition_Ratio\",\n","\"Alphabetic_Ratio\",\n","\"Symbol_Ratio\",\n","\"Vowel_run_count\",\n","\"Consonant_run_count\",\n","\"Vowel_cluster_ratio\",\n","\"Entropy_per_length\",\n","\"Entropy_Slope\",\n","\"Character_Distribution_Symmetry\"\n","\n","\n","\n","\n","]\n","\n","df = pd.read_csv(\"oct30_ndga_v2.csv\")\n","# Remove duplicate columns (keep first occurrence)\n","df = df.loc[:, ~df.columns.duplicated()]\n","\n","# Save filtered data to CSV\n","df_filtered, bounds = filter_outliers(\n","    df, all_features, method=\"iqr\", save_path=\"oct30_ndga_v3.csv\"\n",")\n","\n","print(bounds)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LfLcUtF7nyHh","executionInfo":{"status":"ok","timestamp":1761820024942,"user_tz":-330,"elapsed":30801,"user":{"displayName":"Manoj M J","userId":"05788064290666556527"}},"outputId":"e4cd2a41-45bc-4b5f-9b55-de7e9a6bfb3d"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Filtered dataset (within bounds) saved to oct30_ndga_v3.csv\n","                                      Lower_Bound  Upper_Bound\n","Maximum_Consonants_Cluster           5.000000e-01     4.500000\n","Consonant_count                      1.500000e+00    13.500000\n","Pronounceability_Score               1.041667e-01     0.537500\n","Bigram-Likelihood                    2.112313e+00     4.932612\n","Character_Frequency_Deviation        6.107128e-03     0.066801\n","Unique_Character_Ratio               4.375000e-01     1.137500\n","Unique_Character                     4.500000e+00    16.500000\n","Dictionary_Standard                 -7.500000e-01     1.250000\n","Markov_Chain_Likelihood              5.000000e-01     0.500000\n","Length                               1.000000e+00    25.000000\n","Compression_Ratio                    1.050000e+00     2.250000\n","Bigram_Score                         2.112313e+00     4.932612\n","Trigram_Score                        1.788968e+00     5.018387\n","N-gram_LM_perplexity                 3.853444e+00    10.030726\n","Normal_Character_Frequency_varience  6.107128e-03     0.066801\n","Character_Gini                       8.063272e-01     0.960648\n","KL_Divergence                        5.740420e-01     2.776278\n","Sliding_word_ratio                  -2.500000e-01     0.416667\n","Kolmogorov_Complexity                1.050000e+00     2.250000\n","Renyi_Entropy                        2.157191e+00     4.085798\n","Keyboard_Distance_Score              1.722927e+00     5.538763\n","Min_Levenshtein_To_Popular           3.186275e-02     0.169118\n","Repetition_Ratio                     3.571429e-02     0.321429\n","Alphabetic_Ratio                     7.946429e-01     1.008929\n","Symbol_Ratio                        -1.665335e-16     0.177778\n","Vowel_run_count                      0.000000e+00     8.000000\n","Consonant_run_count                  1.000000e+00     9.000000\n","Vowel_cluster_ratio                 -7.692308e-03     0.217949\n","Entropy_per_length                   9.360411e-02     0.411346\n","Entropy_Slope                        1.916701e-02     0.364258\n","Character_Distribution_Symmetry     -4.182582e-02     0.641138\n"]}]},{"cell_type":"code","source":["df=pd.read_csv('oct30_ndga_v3.csv')\n","df.describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367},"id":"TQIXT4Ain0_y","executionInfo":{"status":"ok","timestamp":1761820036268,"user_tz":-330,"elapsed":3319,"user":{"displayName":"Manoj M J","userId":"05788064290666556527"}},"outputId":"4657796e-1c2f-4449-dfff-60508cd5cb81"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Maximum_Consonants_Cluster  Consonant_count  Pronounceability_Score  \\\n","count               454706.000000    454706.000000           454706.000000   \n","mean                     2.436612         8.068697                0.338539   \n","std                      0.777383         2.093110                0.069524   \n","min                      1.000000         3.000000                0.111111   \n","25%                      2.000000         7.000000                0.294118   \n","50%                      2.000000         8.000000                0.333333   \n","75%                      3.000000        10.000000                0.384615   \n","max                      4.000000        13.000000                0.533333   \n","\n","       Bigram-Likelihood  Character_Frequency_Deviation  \\\n","count      454706.000000                  454706.000000   \n","mean            3.630005                       0.036673   \n","std             0.359127                       0.010007   \n","min             2.500000                       0.014239   \n","25%             3.321928                       0.029463   \n","50%             3.584963                       0.035251   \n","75%             3.906891                       0.043301   \n","max             4.584963                       0.066609   \n","\n","       Unique_Character_Ratio  Unique_Character  Dictionary_Standard  \\\n","count           454706.000000     454706.000000        454706.000000   \n","mean                 0.774857         10.742007             0.177044   \n","std                  0.094647          1.974541             0.279427   \n","min                  0.437500          6.000000             0.000000   \n","25%                  0.705882          9.000000             0.000000   \n","50%                  0.777778         11.000000             0.000000   \n","75%                  0.846154         12.000000             0.500000   \n","max                  0.941176         16.000000             1.000000   \n","\n","       Markov_Chain_Likelihood         Length  ...  Repetition_Ratio  \\\n","count                 454706.0  454706.000000  ...     454706.000000   \n","mean                       0.5      14.110909  ...          0.176914   \n","std                        0.0       3.286992  ...          0.039576   \n","min                        0.5       7.000000  ...          0.083333   \n","25%                        0.5      12.000000  ...          0.150000   \n","50%                        0.5      14.000000  ...          0.166667   \n","75%                        0.5      16.000000  ...          0.200000   \n","max                        0.5      25.000000  ...          0.300000   \n","\n","       Alphabetic_Ratio   Symbol_Ratio  Vowel_run_count  Consonant_run_count  \\\n","count     454706.000000  454706.000000    454706.000000        454706.000000   \n","mean           0.910362       0.087077         4.353514             5.660161   \n","std            0.030982       0.028032         1.339635             1.413821   \n","min            0.800000       0.040000         1.000000             1.000000   \n","25%            0.900000       0.066667         3.000000             5.000000   \n","50%            0.916667       0.083333         4.000000             6.000000   \n","75%            0.933333       0.100000         5.000000             7.000000   \n","max            0.960000       0.176471         8.000000             9.000000   \n","\n","       Vowel_cluster_ratio  Entropy_per_length  Entropy_Slope  \\\n","count        454706.000000       454706.000000  454706.000000   \n","mean              0.101217            0.243560       0.179834   \n","std               0.037521            0.043275       0.045075   \n","min               0.040000            0.132603       0.062547   \n","25%               0.071429            0.210145       0.145248   \n","50%               0.090909            0.241342       0.176640   \n","75%               0.125000            0.272815       0.211065   \n","max               0.214286            0.360234       0.343718   \n","\n","       Character_Distribution_Symmetry     label  \n","count                    454706.000000  454706.0  \n","mean                          0.309662       0.0  \n","std                           0.089103       0.0  \n","min                           0.090909       0.0  \n","25%                           0.251748       0.0  \n","50%                           0.323077       0.0  \n","75%                           0.376923       0.0  \n","max                           0.637681       0.0  \n","\n","[8 rows x 32 columns]"],"text/html":["\n","  <div id=\"df-7bddd680-a0c1-45cb-bd62-cb16caab871e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Maximum_Consonants_Cluster</th>\n","      <th>Consonant_count</th>\n","      <th>Pronounceability_Score</th>\n","      <th>Bigram-Likelihood</th>\n","      <th>Character_Frequency_Deviation</th>\n","      <th>Unique_Character_Ratio</th>\n","      <th>Unique_Character</th>\n","      <th>Dictionary_Standard</th>\n","      <th>Markov_Chain_Likelihood</th>\n","      <th>Length</th>\n","      <th>...</th>\n","      <th>Repetition_Ratio</th>\n","      <th>Alphabetic_Ratio</th>\n","      <th>Symbol_Ratio</th>\n","      <th>Vowel_run_count</th>\n","      <th>Consonant_run_count</th>\n","      <th>Vowel_cluster_ratio</th>\n","      <th>Entropy_per_length</th>\n","      <th>Entropy_Slope</th>\n","      <th>Character_Distribution_Symmetry</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>454706.000000</td>\n","      <td>454706.000000</td>\n","      <td>454706.000000</td>\n","      <td>454706.000000</td>\n","      <td>454706.000000</td>\n","      <td>454706.000000</td>\n","      <td>454706.000000</td>\n","      <td>454706.000000</td>\n","      <td>454706.0</td>\n","      <td>454706.000000</td>\n","      <td>...</td>\n","      <td>454706.000000</td>\n","      <td>454706.000000</td>\n","      <td>454706.000000</td>\n","      <td>454706.000000</td>\n","      <td>454706.000000</td>\n","      <td>454706.000000</td>\n","      <td>454706.000000</td>\n","      <td>454706.000000</td>\n","      <td>454706.000000</td>\n","      <td>454706.0</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>2.436612</td>\n","      <td>8.068697</td>\n","      <td>0.338539</td>\n","      <td>3.630005</td>\n","      <td>0.036673</td>\n","      <td>0.774857</td>\n","      <td>10.742007</td>\n","      <td>0.177044</td>\n","      <td>0.5</td>\n","      <td>14.110909</td>\n","      <td>...</td>\n","      <td>0.176914</td>\n","      <td>0.910362</td>\n","      <td>0.087077</td>\n","      <td>4.353514</td>\n","      <td>5.660161</td>\n","      <td>0.101217</td>\n","      <td>0.243560</td>\n","      <td>0.179834</td>\n","      <td>0.309662</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.777383</td>\n","      <td>2.093110</td>\n","      <td>0.069524</td>\n","      <td>0.359127</td>\n","      <td>0.010007</td>\n","      <td>0.094647</td>\n","      <td>1.974541</td>\n","      <td>0.279427</td>\n","      <td>0.0</td>\n","      <td>3.286992</td>\n","      <td>...</td>\n","      <td>0.039576</td>\n","      <td>0.030982</td>\n","      <td>0.028032</td>\n","      <td>1.339635</td>\n","      <td>1.413821</td>\n","      <td>0.037521</td>\n","      <td>0.043275</td>\n","      <td>0.045075</td>\n","      <td>0.089103</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>0.111111</td>\n","      <td>2.500000</td>\n","      <td>0.014239</td>\n","      <td>0.437500</td>\n","      <td>6.000000</td>\n","      <td>0.000000</td>\n","      <td>0.5</td>\n","      <td>7.000000</td>\n","      <td>...</td>\n","      <td>0.083333</td>\n","      <td>0.800000</td>\n","      <td>0.040000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.040000</td>\n","      <td>0.132603</td>\n","      <td>0.062547</td>\n","      <td>0.090909</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>2.000000</td>\n","      <td>7.000000</td>\n","      <td>0.294118</td>\n","      <td>3.321928</td>\n","      <td>0.029463</td>\n","      <td>0.705882</td>\n","      <td>9.000000</td>\n","      <td>0.000000</td>\n","      <td>0.5</td>\n","      <td>12.000000</td>\n","      <td>...</td>\n","      <td>0.150000</td>\n","      <td>0.900000</td>\n","      <td>0.066667</td>\n","      <td>3.000000</td>\n","      <td>5.000000</td>\n","      <td>0.071429</td>\n","      <td>0.210145</td>\n","      <td>0.145248</td>\n","      <td>0.251748</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>2.000000</td>\n","      <td>8.000000</td>\n","      <td>0.333333</td>\n","      <td>3.584963</td>\n","      <td>0.035251</td>\n","      <td>0.777778</td>\n","      <td>11.000000</td>\n","      <td>0.000000</td>\n","      <td>0.5</td>\n","      <td>14.000000</td>\n","      <td>...</td>\n","      <td>0.166667</td>\n","      <td>0.916667</td>\n","      <td>0.083333</td>\n","      <td>4.000000</td>\n","      <td>6.000000</td>\n","      <td>0.090909</td>\n","      <td>0.241342</td>\n","      <td>0.176640</td>\n","      <td>0.323077</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>3.000000</td>\n","      <td>10.000000</td>\n","      <td>0.384615</td>\n","      <td>3.906891</td>\n","      <td>0.043301</td>\n","      <td>0.846154</td>\n","      <td>12.000000</td>\n","      <td>0.500000</td>\n","      <td>0.5</td>\n","      <td>16.000000</td>\n","      <td>...</td>\n","      <td>0.200000</td>\n","      <td>0.933333</td>\n","      <td>0.100000</td>\n","      <td>5.000000</td>\n","      <td>7.000000</td>\n","      <td>0.125000</td>\n","      <td>0.272815</td>\n","      <td>0.211065</td>\n","      <td>0.376923</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>4.000000</td>\n","      <td>13.000000</td>\n","      <td>0.533333</td>\n","      <td>4.584963</td>\n","      <td>0.066609</td>\n","      <td>0.941176</td>\n","      <td>16.000000</td>\n","      <td>1.000000</td>\n","      <td>0.5</td>\n","      <td>25.000000</td>\n","      <td>...</td>\n","      <td>0.300000</td>\n","      <td>0.960000</td>\n","      <td>0.176471</td>\n","      <td>8.000000</td>\n","      <td>9.000000</td>\n","      <td>0.214286</td>\n","      <td>0.360234</td>\n","      <td>0.343718</td>\n","      <td>0.637681</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 32 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bddd680-a0c1-45cb-bd62-cb16caab871e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7bddd680-a0c1-45cb-bd62-cb16caab871e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7bddd680-a0c1-45cb-bd62-cb16caab871e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-688dca39-1869-4b14-9428-847c19aadfff\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-688dca39-1869-4b14-9428-847c19aadfff')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-688dca39-1869-4b14-9428-847c19aadfff button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["\n","import pandas as pd\n","\n","def select_entries(file, num_entries, output_file='oct30_ndga_v4.csv'):\n","    \"\"\"\n","    Select the user-specified number of entries (rows) from a dataset.\n","\n","    Args:\n","        file (str): Path to the CSV file.\n","\n","        num_entries (int): Number of rows to select.\n","        output_file (str): File to save the selected rows.\n","    \"\"\"\n","    # Load dataset\n","    df = pd.read_csv(file)\n","\n","    # Select first 'num_entries' rows\n","    selected_df = df.head(num_entries)\n","\n","    # Save result\n","    selected_df.to_csv(output_file, index=False)\n","\n","\n","    return selected_df\n","\n","\n","# Example usage:\n","selected = select_entries('oct30_ndga_v3.csv', 446419 )   # get first 100 rows\n","print(selected)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"drQsyFx-oKw8","executionInfo":{"status":"ok","timestamp":1761820535656,"user_tz":-330,"elapsed":24314,"user":{"displayName":"Manoj M J","userId":"05788064290666556527"}},"outputId":"6ba41611-32c5-4631-f91d-789394c6900e"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["                       domain  Maximum_Consonants_Cluster  Consonant_count  \\\n","0           01heiliaomimi.com                           1                6   \n","1       01nextprivate.website                           4               11   \n","2             01transport.com                           3                9   \n","3               0bigazart.com                           2                7   \n","4                  0catch.com                           3                6   \n","...                       ...                         ...              ...   \n","446414          yadlachim.org                           2                8   \n","446415       yado-sagashi.net                           2                8   \n","446416           yadong.party                           3                8   \n","446417          yadongcam.net                           3                8   \n","446418           yadongpan.me                           3                7   \n","\n","        Pronounceability_Score  Bigram-Likelihood  \\\n","0                     0.470588           3.750000   \n","1                     0.333333           4.221928   \n","2                     0.200000           3.807355   \n","3                     0.307692           3.584963   \n","4                     0.200000           3.169925   \n","...                        ...                ...   \n","446414                0.307692           3.584963   \n","446415                0.375000           3.906891   \n","446416                0.250000           3.459432   \n","446417                0.307692           3.584963   \n","446418                0.333333           3.459432   \n","\n","        Character_Frequency_Deviation  Unique_Character_Ratio  \\\n","0                            0.058090                0.647059   \n","1                            0.041876                0.714286   \n","2                            0.028868                0.800000   \n","3                            0.021260                0.923077   \n","4                            0.066144                0.800000   \n","...                               ...                     ...   \n","446414                       0.021260                0.923077   \n","446415                       0.035977                0.812500   \n","446416                       0.033333                0.833333   \n","446417                       0.029669                0.846154   \n","446418                       0.033333                0.833333   \n","\n","        Unique_Character  Dictionary_Standard  Markov_Chain_Likelihood  ...  \\\n","0                     11                  0.0                      0.5  ...   \n","1                     15                  0.0                      0.5  ...   \n","2                     12                  0.5                      0.5  ...   \n","3                     12                  0.0                      0.5  ...   \n","4                      8                  0.5                      0.5  ...   \n","...                  ...                  ...                      ...  ...   \n","446414                12                  0.0                      0.5  ...   \n","446415                13                  0.5                      0.5  ...   \n","446416                10                  0.5                      0.5  ...   \n","446417                11                  0.5                      0.5  ...   \n","446418                10                  0.5                      0.5  ...   \n","\n","        Repetition_Ratio  Alphabetic_Ratio  Symbol_Ratio  Vowel_run_count  \\\n","0               0.235294          0.823529      0.058824                5   \n","1               0.190476          0.857143      0.047619                7   \n","2               0.133333          0.800000      0.066667                3   \n","3               0.153846          0.846154      0.076923                4   \n","4               0.300000          0.800000      0.100000                2   \n","...                  ...               ...           ...              ...   \n","446414          0.153846          0.923077      0.076923                4   \n","446415          0.187500          0.875000      0.125000                6   \n","446416          0.166667          0.916667      0.083333                3   \n","446417          0.153846          0.923077      0.076923                4   \n","446418          0.166667          0.916667      0.083333                4   \n","\n","        Consonant_run_count  Vowel_cluster_ratio  Entropy_per_length  \\\n","0                         6             0.176471            0.189384   \n","1                         7             0.047619            0.175700   \n","2                         5             0.066667            0.233793   \n","3                         6             0.076923            0.272815   \n","4                         4             0.100000            0.284644   \n","...                     ...                  ...                 ...   \n","446414                    5             0.076923            0.272815   \n","446415                    7             0.062500            0.223614   \n","446416                    5             0.083333            0.270969   \n","446417                    6             0.076923            0.260981   \n","446418                    5             0.083333            0.270969   \n","\n","        Entropy_Slope  Character_Distribution_Symmetry  label  \n","0            0.119783                         0.513369      0  \n","1            0.119778                         0.457143      0  \n","2            0.164906                         0.300000      0  \n","3            0.205498                         0.141026      0  \n","4            0.199445                         0.350000      0  \n","...               ...                              ...    ...  \n","446414       0.215987                         0.141026      0  \n","446415       0.147105                         0.317308      0  \n","446416       0.209647                         0.266667      0  \n","446417       0.188887                         0.251748      0  \n","446418       0.191267                         0.266667      0  \n","\n","[446419 rows x 33 columns]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","def combine_datasets(file1, file2, output_file=\"combined.csv\"):\n","    \"\"\"\n","    Combine two datasets without altering datapoints.\n","    The header of the second dataset is removed automatically.\n","    \"\"\"\n","    # Load first dataset normally (with header)\n","    df1 = pd.read_csv(file1)\n","\n","    # Load second dataset as raw, then reassign columns from df1\n","    df2 = pd.read_csv(file2, header=None, skiprows=1)\n","    df2.columns = df1.columns  # assign the same header as df1\n","\n","    # Concatenate without altering datapoints\n","    combined_df = pd.concat([df1, df2], ignore_index=True)\n","\n","    # Save to CSV\n","    combined_df.to_csv(output_file, index=False)\n","    return combined_df\n","\n","\n","\n","# Example usage:\n","combined = combine_datasets('oct30_dga_v3.csv', 'oct30_ndga_v4.csv')\n","print(combined.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XVf8PP3toOM5","executionInfo":{"status":"ok","timestamp":1761820594724,"user_tz":-330,"elapsed":52865,"user":{"displayName":"Manoj M J","userId":"05788064290666556527"}},"outputId":"2489ec10-65cc-4296-8a53-ce43322f226f"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["                 domain  Maximum_Consonants_Cluster  Consonant_count  \\\n","0   ofdhiydrrttpblp.com                          10               15   \n","1    osvwkptpwqyiqen.ru                          10               13   \n","2  wwcdhdhijsfsuyr.info                           7               15   \n","3    fhhvhiqlrtwpnik.ru                           7               14   \n","4   gwgweakshkaxnqv.org                           4               14   \n","\n","   Pronounceability_Score  Bigram-Likelihood  Character_Frequency_Deviation  \\\n","0                0.157895           4.169925                       0.025219   \n","1                0.222222           4.087463                       0.022222   \n","2                0.200000           4.142664                       0.024744   \n","3                0.166667           4.087463                       0.032723   \n","4                0.210526           4.058814                       0.032120   \n","\n","   Unique_Character_Ratio  Unique_Character  Dictionary_Standard  \\\n","0                0.736842                14                  0.0   \n","1                0.833333                15                  0.0   \n","2                0.700000                14                  0.0   \n","3                0.777778                14                  0.0   \n","4                0.736842                14                  0.0   \n","\n","   Markov_Chain_Likelihood  ...  Repetition_Ratio  Alphabetic_Ratio  \\\n","0                 0.555556  ...          0.105263          0.947368   \n","1                 0.500000  ...          0.111111          0.944444   \n","2                 0.526316  ...          0.100000          0.950000   \n","3                 0.529412  ...          0.166667          0.944444   \n","4                 0.500000  ...          0.157895          0.947368   \n","\n","   Symbol_Ratio  Vowel_run_count  Consonant_run_count  Vowel_cluster_ratio  \\\n","0      0.052632                3                    4             0.052632   \n","1      0.055556                4                    4             0.055556   \n","2      0.050000                4                    4             0.050000   \n","3      0.055556                3                    4             0.055556   \n","4      0.052632                3                    4             0.105263   \n","\n","   Entropy_per_length  Entropy_Slope  Character_Distribution_Symmetry  label  \n","0            0.195874       0.131372                         0.338346      1  \n","1            0.213144       0.145240                         0.266667      1  \n","2            0.186096       0.170642                         0.342857      1  \n","3            0.204641       0.182950                         0.349206      1  \n","4            0.193783       0.172435                         0.375940      1  \n","\n","[5 rows x 33 columns]\n"]}]},{"cell_type":"code","source":["# =========================\n","# DGA Detection Optimized (31 Features)\n","# =========================\n","\n","import re, math, string, zlib\n","import pandas as pd\n","import numpy as np\n","from collections import Counter\n","from difflib import SequenceMatcher\n","import joblib\n","from nltk.corpus import words as nltk_words\n","import nltk\n","from xgboost import XGBClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# -------------------------\n","# Download English Words\n","# -------------------------\n","try:\n","    nltk.data.find(\"corpora/words\")\n","except LookupError:\n","    nltk.download(\"words\")\n","\n","ENGLISH_WORDS = set(w.lower() for w in nltk_words.words())\n","VOWELS = set(\"aeiou\")\n","CONSONANTS = set(string.ascii_lowercase) - VOWELS\n","ALPHABET = string.ascii_lowercase\n","POP_DOMAINS = [\"google\", \"facebook\", \"youtube\", \"amazon\", \"twitter\", \"instagram\"]\n","\n","# Precompute keyboard positions\n","KEYBOARD_POS = {c: (i // 10, i % 10) for i, c in enumerate(\"qwertyuiopasdfghjklzxcvbnm\")}\n","\n","# -------------------------\n","# Utility Functions\n","# -------------------------\n","def safe(s): return str(s).lower() if isinstance(s, str) else \"\"\n","\n","def shannon_entropy(s):\n","    if not s: return 0.0\n","    freq = Counter(s)\n","    probs = np.array(list(freq.values()), dtype=float) / len(s)\n","    return -np.sum(probs * np.log2(probs + 1e-12))\n","\n","def renyi_entropy(s, alpha=2):\n","    if not s: return 0.0\n","    freq = Counter(s)\n","    probs = np.array(list(freq.values()), dtype=float) / len(s)\n","    return 1.0 / (1.0 - alpha) * np.log2(np.sum(probs ** alpha) + 1e-12)\n","\n","def kolmogorov_complexity(s):\n","    if not s: return 0.0\n","    comp = zlib.compress(s.encode(\"utf-8\"))\n","    return len(comp) / max(1, len(s))\n","\n","def bigram_likelihood(s):\n","    if len(s) < 2: return 0.0\n","    bigrams = [s[i:i+2] for i in range(len(s)-1)]\n","    freq = Counter(bigrams)\n","    probs = np.array(list(freq.values())) / len(bigrams)\n","    return -np.sum(probs * np.log2(probs + 1e-12))\n","\n","def trigram_score(s):\n","    if len(s) < 3: return 0.0\n","    trigrams = [s[i:i+3] for i in range(len(s)-2)]\n","    freq = Counter(trigrams)\n","    probs = np.array(list(freq.values())) / len(trigrams)\n","    return -np.sum(probs * np.log2(probs + 1e-12))\n","\n","def char_freq_dev(s):\n","    if not s: return 0.0\n","    freq = np.array(list(Counter(s).values()))\n","    return np.std(freq / np.sum(freq))\n","\n","def char_gini(s):\n","    if not s: return 0.0\n","    freq = np.array(list(Counter(s).values()), dtype=float)\n","    p = freq / freq.sum()\n","    return 1.0 - np.sum(p**2)\n","\n","def vowel_consonant_features(s):\n","    v_runs = re.findall(r\"[aeiou]+\", s)\n","    c_runs = re.findall(r\"[bcdfghjklmnpqrstvwxyz]+\", s)\n","    v_run_count = len(v_runs)\n","    c_run_count = len(c_runs)\n","    v_cluster_ratio = max((len(r) for r in v_runs), default=0) / max(1, len(s))\n","    return v_run_count, c_run_count, v_cluster_ratio\n","\n","def max_consonant_cluster(s):\n","    clusters = re.findall(r\"[bcdfghjklmnpqrstvwxyz]+\", s)\n","    return max((len(c) for c in clusters), default=0)\n","\n","def pronounceability_score(s):\n","    if not s: return 0.0\n","    return sum(c in VOWELS for c in s) / max(1, len(s))\n","\n","def unique_char_ratio(s): return len(set(s)) / max(1, len(s))\n","def unique_char(s): return len(set(s))\n","\n","def dict_std(s):\n","    if not s: return 0.0\n","    words_found = sum(w in ENGLISH_WORDS for w in re.findall(r\"[a-z]+\", s))\n","    return words_found / max(1, len(s.split(\".\")))\n","\n","def markov_chain_likelihood(s):\n","    if len(s) < 2: return 0.0\n","    probs = [1.0 if s[i] == s[i-1] else 0.5 for i in range(1, len(s))]\n","    return np.mean(probs)\n","\n","def kl_divergence(s):\n","    benign_dist = np.ones(26) / 26\n","    if not s: return 0.0\n","    counts = np.array([s.count(c) for c in ALPHABET], dtype=float)\n","    if counts.sum() == 0: return 0.0\n","    p = counts / counts.sum()\n","    return np.sum(p * np.log2((p + 1e-12) / (benign_dist + 1e-12)))\n","\n","def sliding_word_ratio(s):\n","    if len(s) < 4: return 0.0\n","    matches = sum(s[i:i+4] in ENGLISH_WORDS for i in range(len(s)-3))\n","    return matches / (len(s) - 3)\n","\n","def keyboard_distance_score(s):\n","    total = count = 0.0\n","    for a, b in zip(s, s[1:]):\n","        if a in KEYBOARD_POS and b in KEYBOARD_POS:\n","            total += math.dist(KEYBOARD_POS[a], KEYBOARD_POS[b])\n","            count += 1\n","    return total / count if count else 0.0\n","\n","def min_levenshtein_to_popular(s):\n","    return min(SequenceMatcher(None, s, p).ratio() for p in POP_DOMAINS)\n","\n","def repetition_ratio(s):\n","    if not s: return 0.0\n","    freq = Counter(s)\n","    return max(freq.values()) / len(s)\n","\n","def alphabetic_ratio(s):\n","    return sum(c.isalpha() for c in s) / max(1, len(s))\n","\n","def symbol_ratio(s):\n","    return sum(not c.isalnum() for c in s) / max(1, len(s))\n","\n","def entropy_per_length(s):\n","    return shannon_entropy(s) / max(1, len(s))\n","\n","def entropy_slope(s):\n","    if len(s) < 2: return 0.0\n","    entropies = [shannon_entropy(s[:i]) for i in range(2, len(s)+1)]\n","    x = np.arange(2, len(s)+1)\n","    slope, _ = np.polyfit(x, entropies, 1)\n","    return slope\n","\n","def char_distribution_symmetry(s):\n","    if not s: return 0.0\n","    freq = np.array(list(Counter(s).values()), dtype=float)\n","    mean = freq.mean()\n","    return np.mean(np.abs(freq - mean)) / mean\n","\n","# -------------------------\n","# Feature Extraction (31 features)\n","# -------------------------\n","def extract_features(domain):\n","    s = safe(domain)\n","    v_run, c_run, v_ratio = vowel_consonant_features(s)\n","    return {\n","        \"Maximum_Consonants_Cluster\": max_consonant_cluster(s),\n","        \"Consonant_count\": sum(c in CONSONANTS for c in s),\n","        \"Pronounceability_Score\": pronounceability_score(s),\n","        \"Bigram-Likelihood\": bigram_likelihood(s),\n","        \"Character_Frequency_Deviation\": char_freq_dev(s),\n","        \"Unique_Character_Ratio\": unique_char_ratio(s),\n","        \"Unique_Character\": unique_char(s),\n","        \"Dictionary_Standard\": dict_std(s),\n","        \"Markov_Chain_Likelihood\": markov_chain_likelihood(s),\n","        \"Length\": len(s),\n","        \"Compression_Ratio\": kolmogorov_complexity(s),\n","        \"Bigram_Score\": bigram_likelihood(s),\n","        \"Trigram_Score\": trigram_score(s),\n","        \"N-gram_LM_perplexity\": bigram_likelihood(s) + trigram_score(s),\n","        \"Normal_Character_Frequency_varience\": char_freq_dev(s),\n","        \"Character_Gini\": char_gini(s),\n","        \"KL_Divergence\": kl_divergence(s),\n","        \"Sliding_word_ratio\": sliding_word_ratio(s),\n","        \"Kolmogorov_Complexity\": kolmogorov_complexity(s),\n","        \"Renyi_Entropy\": renyi_entropy(s),\n","        \"Keyboard_Distance_Score\": keyboard_distance_score(s),\n","        \"Min_Levenshtein_To_Popular\": min_levenshtein_to_popular(s),\n","        \"Repetition_Ratio\": repetition_ratio(s),\n","        \"Alphabetic_Ratio\": alphabetic_ratio(s),\n","        \"Symbol_Ratio\": symbol_ratio(s),\n","        \"Vowel_run_count\": v_run,\n","        \"Consonant_run_count\": c_run,\n","        \"Vowel_cluster_ratio\": v_ratio,\n","        \"Entropy_per_length\": entropy_per_length(s),\n","        \"Entropy_Slope\": entropy_slope(s),\n","        \"Character_Distribution_Symmetry\": char_distribution_symmetry(s),\n","    }\n","\n","def compute_features_for_dataset(df, domain_col=\"domain\"):\n","    feats = [extract_features(d) for d in df[domain_col]]\n","    return pd.DataFrame(feats)\n","\n","# -------------------------\n","# Model Training\n","# -------------------------\n","def train_model(train_file, label_col=\"label\", model_type=\"xgboost\", save_model=\"dga_model.pkl\"):\n","    df = pd.read_csv(train_file)\n","    drop_cols = [label_col]\n","    if \"domain\" in df.columns:\n","        drop_cols.append(\"domain\")\n","    X = df.drop(columns=drop_cols).apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n","    y = df[label_col]\n","\n","    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\") if model_type == \"xgboost\" \\\n","        else RandomForestClassifier(n_estimators=200, random_state=42)\n","\n","    model.fit(X_train, y_train)\n","    preds = model.predict(X_val)\n","    print(\"Validation Accuracy:\", accuracy_score(y_val, preds))\n","    print(classification_report(y_val, preds))\n","    joblib.dump(model, save_model)\n","    print(f\"✅ Model saved to {save_model}\")\n","    return model\n","\n","# -------------------------\n","# Prediction\n","# -------------------------\n","def predict_new(test_file, model_file=\"dga_model.pkl\", output_file=\"predictions_dga.csv\"):\n","    df_test = pd.read_csv(test_file)\n","    domain_col = \"domain\" if \"domain\" in df_test.columns else df_test.columns[0]\n","    X_test = compute_features_for_dataset(df_test, domain_col).apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n","    model = joblib.load(model_file)\n","    preds = model.predict(X_test)\n","    df_out = df_test.copy()\n","    df_out[\"Prediction\"] = preds\n","    df_out.to_csv(output_file, index=False)\n","    print(f\"✅ Predictions saved to {output_file}\")\n","    return df_out\n","\n","# -------------------------\n","# Example Usage\n","# -------------------------\n","if __name__ == \"__main__\":\n","    model = train_model(\"combined.csv\", label_col=\"label\", model_type=\"xgboost\")\n","    results = predict_new(\"dataset_dga.csv\", model_file=\"dga_model.pkl\")\n","    print(results.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3zsou1FWsALE","outputId":"07a99e59-ff59-46d3-9b76-2c0e1c51c35f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:00:37] WARNING: /workspace/src/learner.cc:790: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  bst.update(dtrain, iteration=i, fobj=obj)\n"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 0.9819676537789526\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.98      0.98     89347\n","           1       0.98      0.98      0.98     89221\n","\n","    accuracy                           0.98    178568\n","   macro avg       0.98      0.98      0.98    178568\n","weighted avg       0.98      0.98      0.98    178568\n","\n","✅ Model saved to dga_model.pkl\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","def count_zero_one(df, column_name):\n","    \"\"\"\n","    Count how many entries are 0 or 1 in a specific column.\n","\n","    Parameters:\n","    -----------\n","    df : pd.DataFrame\n","        Input dataset\n","    column_name : str\n","        Column to check\n","\n","    Returns:\n","    --------\n","    dict : counts of 0 and 1\n","    \"\"\"\n","    if column_name not in df.columns:\n","        raise ValueError(f\"Column '{column_name}' not found in dataset\")\n","\n","    counts = {\n","        \"count_0\": (df[column_name] == 0).sum(),\n","        \"count_1\": (df[column_name] == 1).sum()\n","    }\n","    return counts\n","\n","\n","# ==== Example Usage ====\n","df = pd.read_csv(\"predictions_dga.csv\")\n","\n","# Replace \"Label\" with your column name\n","result = count_zero_one(df, \"Prediction\")\n","\n","print(f\"Number of 0s: {result['count_0']}\")\n","print(f\"Number of 1s: {result['count_1']}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mfxn6p5CwzhS","executionInfo":{"status":"ok","timestamp":1761821849261,"user_tz":-330,"elapsed":76,"user":{"displayName":"Manoj M J","userId":"05788064290666556527"}},"outputId":"304ada30-4839-4031-b422-f551073804f3"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of 0s: 332\n","Number of 1s: 2168\n"]}]},{"cell_type":"code","source":["files.download(\"combined.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"ccCE7VWKuWJH","executionInfo":{"status":"ok","timestamp":1761821177308,"user_tz":-330,"elapsed":48,"user":{"displayName":"Manoj M J","userId":"05788064290666556527"}},"outputId":"789f8c55-1179-43a6-bd70-9172775f1df6"},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_7dfc5240-9f72-4964-a05c-107c415fd345\", \"combined.csv\", 378704699)"]},"metadata":{}}]},{"cell_type":"code","source":["# =========================\n","# DGA Detection Optimized (31 Features)\n","# =========================\n","\n","import re, math, string, zlib\n","import pandas as pd\n","import numpy as np\n","from collections import Counter\n","from difflib import SequenceMatcher\n","import joblib\n","from nltk.corpus import words as nltk_words\n","import nltk\n","from xgboost import XGBClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# -------------------------\n","# Download English Words\n","# -------------------------\n","try:\n","    nltk.data.find(\"corpora/words\")\n","except LookupError:\n","    nltk.download(\"words\")\n","\n","ENGLISH_WORDS = set(w.lower() for w in nltk_words.words())\n","VOWELS = set(\"aeiou\")\n","CONSONANTS = set(string.ascii_lowercase) - VOWELS\n","ALPHABET = string.ascii_lowercase\n","POP_DOMAINS = [\"google\", \"facebook\", \"youtube\", \"amazon\", \"twitter\", \"instagram\"]\n","\n","# Precompute keyboard positions\n","KEYBOARD_POS = {c: (i // 10, i % 10) for i, c in enumerate(\"qwertyuiopasdfghjklzxcvbnm\")}\n","\n","# -------------------------\n","# Utility Functions\n","# -------------------------\n","def safe(s): return str(s).lower() if isinstance(s, str) else \"\"\n","\n","def shannon_entropy(s):\n","    if not s: return 0.0\n","    freq = Counter(s)\n","    probs = np.array(list(freq.values()), dtype=float) / len(s)\n","    return -np.sum(probs * np.log2(probs + 1e-12))\n","\n","def renyi_entropy(s, alpha=2):\n","    if not s: return 0.0\n","    freq = Counter(s)\n","    probs = np.array(list(freq.values()), dtype=float) / len(s)\n","    return 1.0 / (1.0 - alpha) * np.log2(np.sum(probs ** alpha) + 1e-12)\n","\n","def kolmogorov_complexity(s):\n","    if not s: return 0.0\n","    comp = zlib.compress(s.encode(\"utf-8\"))\n","    return len(comp) / max(1, len(s))\n","\n","def bigram_likelihood(s):\n","    if len(s) < 2: return 0.0\n","    bigrams = [s[i:i+2] for i in range(len(s)-1)]\n","    freq = Counter(bigrams)\n","    probs = np.array(list(freq.values())) / len(bigrams)\n","    return -np.sum(probs * np.log2(probs + 1e-12))\n","\n","def trigram_score(s):\n","    if len(s) < 3: return 0.0\n","    trigrams = [s[i:i+3] for i in range(len(s)-2)]\n","    freq = Counter(trigrams)\n","    probs = np.array(list(freq.values())) / len(trigrams)\n","    return -np.sum(probs * np.log2(probs + 1e-12))\n","\n","def char_freq_dev(s):\n","    if not s: return 0.0\n","    freq = np.array(list(Counter(s).values()))\n","    return np.std(freq / np.sum(freq))\n","\n","def char_gini(s):\n","    if not s: return 0.0\n","    freq = np.array(list(Counter(s).values()), dtype=float)\n","    p = freq / freq.sum()\n","    return 1.0 - np.sum(p**2)\n","\n","def vowel_consonant_features(s):\n","    v_runs = re.findall(r\"[aeiou]+\", s)\n","    c_runs = re.findall(r\"[bcdfghjklmnpqrstvwxyz]+\", s)\n","    v_run_count = len(v_runs)\n","    c_run_count = len(c_runs)\n","    v_cluster_ratio = max((len(r) for r in v_runs), default=0) / max(1, len(s))\n","    return v_run_count, c_run_count, v_cluster_ratio\n","\n","def max_consonant_cluster(s):\n","    clusters = re.findall(r\"[bcdfghjklmnpqrstvwxyz]+\", s)\n","    return max((len(c) for c in clusters), default=0)\n","\n","def pronounceability_score(s):\n","    if not s: return 0.0\n","    return sum(c in VOWELS for c in s) / max(1, len(s))\n","\n","def unique_char_ratio(s): return len(set(s)) / max(1, len(s))\n","def unique_char(s): return len(set(s))\n","\n","def dict_std(s):\n","    if not s: return 0.0\n","    words_found = sum(w in ENGLISH_WORDS for w in re.findall(r\"[a-z]+\", s))\n","    return words_found / max(1, len(s.split(\".\")))\n","\n","def markov_chain_likelihood(s):\n","    if len(s) < 2: return 0.0\n","    probs = [1.0 if s[i] == s[i-1] else 0.5 for i in range(1, len(s))]\n","    return np.mean(probs)\n","\n","def kl_divergence(s):\n","    benign_dist = np.ones(26) / 26\n","    if not s: return 0.0\n","    counts = np.array([s.count(c) for c in ALPHABET], dtype=float)\n","    if counts.sum() == 0: return 0.0\n","    p = counts / counts.sum()\n","    return np.sum(p * np.log2((p + 1e-12) / (benign_dist + 1e-12)))\n","\n","def sliding_word_ratio(s):\n","    if len(s) < 4: return 0.0\n","    matches = sum(s[i:i+4] in ENGLISH_WORDS for i in range(len(s)-3))\n","    return matches / (len(s) - 3)\n","\n","def keyboard_distance_score(s):\n","    total = count = 0.0\n","    for a, b in zip(s, s[1:]):\n","        if a in KEYBOARD_POS and b in KEYBOARD_POS:\n","            total += math.dist(KEYBOARD_POS[a], KEYBOARD_POS[b])\n","            count += 1\n","    return total / count if count else 0.0\n","\n","def min_levenshtein_to_popular(s):\n","    return min(SequenceMatcher(None, s, p).ratio() for p in POP_DOMAINS)\n","\n","def repetition_ratio(s):\n","    if not s: return 0.0\n","    freq = Counter(s)\n","    return max(freq.values()) / len(s)\n","\n","def alphabetic_ratio(s):\n","    return sum(c.isalpha() for c in s) / max(1, len(s))\n","\n","def symbol_ratio(s):\n","    return sum(not c.isalnum() for c in s) / max(1, len(s))\n","\n","def entropy_per_length(s):\n","    return shannon_entropy(s) / max(1, len(s))\n","\n","def entropy_slope(s):\n","    if len(s) < 2: return 0.0\n","    entropies = [shannon_entropy(s[:i]) for i in range(2, len(s)+1)]\n","    x = np.arange(2, len(s)+1)\n","    slope, _ = np.polyfit(x, entropies, 1)\n","    return slope\n","\n","def char_distribution_symmetry(s):\n","    if not s: return 0.0\n","    freq = np.array(list(Counter(s).values()), dtype=float)\n","    mean = freq.mean()\n","    return np.mean(np.abs(freq - mean)) / mean\n","\n","# -------------------------\n","# Feature Extraction (31 features)\n","# -------------------------\n","def extract_features(domain):\n","    s = safe(domain)\n","    v_run, c_run, v_ratio = vowel_consonant_features(s)\n","    return {\n","        \"Maximum_Consonants_Cluster\": max_consonant_cluster(s),\n","        \"Consonant_count\": sum(c in CONSONANTS for c in s),\n","        \"Pronounceability_Score\": pronounceability_score(s),\n","        \"Bigram-Likelihood\": bigram_likelihood(s),\n","        \"Character_Frequency_Deviation\": char_freq_dev(s),\n","        \"Unique_Character_Ratio\": unique_char_ratio(s),\n","        \"Unique_Character\": unique_char(s),\n","        \"Dictionary_Standard\": dict_std(s),\n","        \"Markov_Chain_Likelihood\": markov_chain_likelihood(s),\n","        \"Length\": len(s),\n","        \"Compression_Ratio\": kolmogorov_complexity(s),\n","        \"Bigram_Score\": bigram_likelihood(s),\n","        \"Trigram_Score\": trigram_score(s),\n","        \"N-gram_LM_perplexity\": bigram_likelihood(s) + trigram_score(s),\n","        \"Normal_Character_Frequency_varience\": char_freq_dev(s),\n","        \"Character_Gini\": char_gini(s),\n","        \"KL_Divergence\": kl_divergence(s),\n","        \"Sliding_word_ratio\": sliding_word_ratio(s),\n","        \"Kolmogorov_Complexity\": kolmogorov_complexity(s),\n","        \"Renyi_Entropy\": renyi_entropy(s),\n","        \"Keyboard_Distance_Score\": keyboard_distance_score(s),\n","        \"Min_Levenshtein_To_Popular\": min_levenshtein_to_popular(s),\n","        \"Repetition_Ratio\": repetition_ratio(s),\n","        \"Alphabetic_Ratio\": alphabetic_ratio(s),\n","        \"Symbol_Ratio\": symbol_ratio(s),\n","        \"Vowel_run_count\": v_run,\n","        \"Consonant_run_count\": c_run,\n","        \"Vowel_cluster_ratio\": v_ratio,\n","        \"Entropy_per_length\": entropy_per_length(s),\n","        \"Entropy_Slope\": entropy_slope(s),\n","        \"Character_Distribution_Symmetry\": char_distribution_symmetry(s),\n","    }\n","\n","def compute_features_for_dataset(df, domain_col=\"domain\"):\n","    feats = [extract_features(d) for d in df[domain_col]]\n","    return pd.DataFrame(feats)\n","\n","# -------------------------\n","# Model Training\n","# -------------------------\n","def train_model(train_file, label_col=\"label\", model_type=\"xgboost\", save_model=\"dga_model.pkl\"):\n","    df = pd.read_csv(train_file)\n","    drop_cols = [label_col]\n","    if \"domain\" in df.columns:\n","        drop_cols.append(\"domain\")\n","    X = df.drop(columns=drop_cols).apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n","    y = df[label_col]\n","\n","    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\") if model_type == \"xgboost\" \\\n","        else RandomForestClassifier(n_estimators=200, random_state=42)\n","\n","    model.fit(X_train, y_train)\n","    preds = model.predict(X_val)\n","    print(\"Validation Accuracy:\", accuracy_score(y_val, preds))\n","    print(classification_report(y_val, preds))\n","    joblib.dump(model, save_model)\n","    print(f\"✅ Model saved to {save_model}\")\n","    return model\n","\n","# -------------------------\n","# Prediction\n","# -------------------------\n","def predict_new(test_file, model_file=\"dga_model.pkl\", output_file=\"predictions_ndga.csv\"):\n","    df_test = pd.read_csv(test_file)\n","    domain_col = \"domain\" if \"domain\" in df_test.columns else df_test.columns[0]\n","    X_test = compute_features_for_dataset(df_test, domain_col).apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n","    model = joblib.load(model_file)\n","    preds = model.predict(X_test)\n","    df_out = df_test.copy()\n","    df_out[\"Prediction\"] = preds\n","    df_out.to_csv(output_file, index=False)\n","    print(f\"✅ Predictions saved to {output_file}\")\n","    return df_out\n","\n","# -------------------------\n","# Example Usage\n","# -------------------------\n","if __name__ == \"__main__\":\n","    model = train_model(\"combined.csv\", label_col=\"label\", model_type=\"xgboost\")\n","    results = predict_new(\"dataset_ndga.csv\", model_file=\"dga_model.pkl\")\n","    print(results.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NtsVWy2ZubUB","executionInfo":{"status":"ok","timestamp":1761821949095,"user_tz":-330,"elapsed":21990,"user":{"displayName":"Manoj M J","userId":"05788064290666556527"}},"outputId":"9e8d7840-0e93-4195-c4e6-f1a3d1828921"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [10:58:58] WARNING: /workspace/src/learner.cc:790: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  bst.update(dtrain, iteration=i, fobj=obj)\n"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 0.9819676537789526\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.98      0.98     89347\n","           1       0.98      0.98      0.98     89221\n","\n","    accuracy                           0.98    178568\n","   macro avg       0.98      0.98      0.98    178568\n","weighted avg       0.98      0.98      0.98    178568\n","\n","✅ Model saved to dga_model.pkl\n","✅ Predictions saved to predictions_ndga.csv\n","              domains  Prediction\n","0        eldenvpn.net           0\n","1  mrworldpremiere.tv           1\n","2           xpjfw.com           1\n","3  kvdveganbeauty.com           0\n","4        officient.io           0\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","def count_zero_one(df, column_name):\n","    \"\"\"\n","    Count how many entries are 0 or 1 in a specific column.\n","\n","    Parameters:\n","    -----------\n","    df : pd.DataFrame\n","        Input dataset\n","    column_name : str\n","        Column to check\n","\n","    Returns:\n","    --------\n","    dict : counts of 0 and 1\n","    \"\"\"\n","    if column_name not in df.columns:\n","        raise ValueError(f\"Column '{column_name}' not found in dataset\")\n","\n","    counts = {\n","        \"count_0\": (df[column_name] == 0).sum(),\n","        \"count_1\": (df[column_name] == 1).sum()\n","    }\n","    return counts\n","\n","\n","# ==== Example Usage ====\n","df = pd.read_csv(\"predictions_ndga.csv\")\n","\n","# Replace \"Label\" with your column name\n","result = count_zero_one(df, \"Prediction\")\n","\n","print(f\"Number of 0s: {result['count_0']}\")\n","print(f\"Number of 1s: {result['count_1']}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QbRaManPxSXu","executionInfo":{"status":"ok","timestamp":1761821955509,"user_tz":-330,"elapsed":12,"user":{"displayName":"Manoj M J","userId":"05788064290666556527"}},"outputId":"3790204a-df99-4217-ad5e-d0b9875f6878"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of 0s: 1959\n","Number of 1s: 541\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Lo40iOszxZT7"},"execution_count":null,"outputs":[]}]}